
#### Aim of prog: Gathering tool functions, note that the required packages are not loaded here
## Table of Contents
#	- getParams: Get fixed values parameters
#	- getLastRun: Get name of the last run
#	- lazyTrace: Bayesplot is having troubles on my mac (Arial font not always found), so I create my own traces plot
#	- reshapeDraws: Function to reshape draws_array
#	- lazyPosterior: Function to plot the prior and posterior of a parameter
#	- lazyComparePosterior: Function to plot the posteriors of a parameter from a list of models
#	- expand: Function to expand the basic names when there is more than one NFI
#	- energyPairs: Function to do a pair plot of parameters versus energy
#	- isProcessed: Detect if a species has been processed or not
#	- centralised_fct: Wrapping function to call all the other plot functions and to gather informations on the runs
#	- plot_correl_error: Function to plot the correlations energy <--> parameters for each species, and to plot rescaled error values
#	- checkFunnels: Function to check if plotting one parameter against others shows some funnel structures
#	- dbh_timeSeries: Function to plot latent dbh states time series (posteriorSim is generated by the centralised function)
#	- rescaleParams: Function to rescale parameters (intercept and slopes)
#	- computeGrowth: Function to compute growth, the data table must be sorted by year within tree id and plot id
#	- growth_fct: Function computing the expected growth in the case growth ~ lognormal.
#	- growth_fct_meanlog: Function computing the expected growth on the log scale (i.e., parameter meanlog of lognormal distribution)
#	- optimumPredictorValue: Function to compute the optimum value of response variables with a quadratic term
#	- plotGrowth: Function to plot growth vs a response variable with the uncertainty related to parameters estimation (minus process error)
#	- getEnvSeries: Function to get the environment for a given species and run (i.e., a given index set)
#	- validationTreeRing: Function to compare tree ring time-series with simulated time series from the fitted models
#	- infoSpecies: Function to give species-specific range and dataset range of predictors and dbh

#
## Comments
# This R file contains tool functions only that help me to analyse the results and do some check-up. Note that some functions are quite
#	similar to bayesplot, but I use base plot rather than ggplot. Moreover, Bayesplot is having troubles on my mac (Arial font not always
#	found), so I created my own traces and posterior plots.

#### Tool functions
## Get fixed values parameters
getParams = function(model_cmdstan, params_names, type = "mean")
{
	if (!(type %in% c("mean", "median", "quantile")))
		stop("Unknown type. Please choose median, quantile, or mean")
	
	if (type != "quantile")
	{
		vals = numeric(length(params_names))
		names(vals) = params_names
		for (i in seq_along(params_names))
		{
			vals[i] = ifelse(type == "mean",
				mean(model_cmdstan$draws(params_names[i])),
				median(model_cmdstan$draws(params_names[i])))
		}
	} else {
		vals = data.table(parameter = params_names, q5 = 0, med = 0, avg = 0, q95 = 0)
		for (i in seq_along(params_names))
		{
			vals[i, c("q5", "med", "q95") := as.list(quantile(model_cmdstan$draws(params_names[i]), c(0.05, 0.5, 0.95)))]
			vals[i, avg := mean(model_cmdstan$draws(params_names[i]))]
		}
	}
	
	return(vals)
}

## Get name of the last run
getLastRun = function(path, begin = "^growth-", extension = ".rds$", format = "ymd", run = NULL, getAll = FALSE, hour = TRUE)
{
	if (format != "ymd")
		stop("Format is not recognised. For now only year-month-day alias ymd works")
	
	if (!is.null(run))
	{
		print(paste("Searching among runs =", run))
		begin = paste0(begin, "run=", run, "-")
	}
	
	ls_files = list.files(path = path, pattern = paste0(begin, ".*", extension))

	if (length(ls_files) == 0)
	{
		warning(paste0("No file detected in the folder '", path, "'. You were looking for '", begin, "*", extension, "'"))
		return(list(file = NA, time_ended = NA))
	}

	if (is.null(run))
		ls_files = ls_files[!stri_detect(str = ls_files, regex = paste0(begin, "run="))]

	ls_files_split = stri_split(
		str = stri_sub(str = ls_files,
			from = stri_locate(ls_files, regex = begin)[, "end"] + 1,
			to = stri_locate_last(ls_files, regex = "_[[:digit:]].*.rds")[, "start"] - 1),
		regex = "-", simplify = TRUE)
	
	if (format == "ymd") # year month day
		dt = data.table(file = ls_files, year = ls_files_split[, 1], month = ls_files_split[, 2], day = ls_files_split[, 3])

	if (hour)
	{
		dt[, c("hour", "minute") := as.list(stri_split(str = stri_sub(str = file,
				from = stri_locate_first(file, regex = "_")[, "end"] + 1,
				to = stri_locate_first(file, regex = "_")[, "end"] + 5),
			regex = "h", simplify = TRUE)), by = file]
	}

	dt[stri_detect(str = day, regex = extension), day := stri_sub(str = day, to = stri_locate_first(str = day, regex = "_")[, "start"] - 1)]

	setorder(dt, year, month, day, hour, minute)
	if (getAll)
		return(list(file = dt[.N, file], time_ended = paste(dt[.N, year], dt[.N, month], dt[.N, day], sep = "-"), allFiles = dt))

	if (hour)
		return(list(file = dt[.N, file], time_ended = paste(dt[.N, year], dt[.N, month], dt[.N, day], sep = "-"),
			hour = paste(dt[.N, hour], dt[.N, minute], sep = "h")))
	
	return(list(file = dt[.N, file], time_ended = paste(dt[.N, year], dt[.N, month], dt[.N, day], sep = "-")))
}

## Bayesplot is having troubles on my mac (Arial font not always found), so I create my own traces plot
lazyTrace = function(draws, filename = NULL, run = NULL, ...)
{
	if (!is.array(draws) && !all(class(draws) %in% c("draws_array", "draws", "array")))
		stop("The class of draws should be either array, or compatible with cmdstanr (draws_array, draws, array)")
	
	n_chains = dim(draws)[2]
	n_iter = dim(draws)[1]
	colours = MetBrewer::met.brewer("Hokusai3", n_chains)
	colours_str = grDevices::colorRampPalette(colours)(n_chains)

	min_val = min(draws)
	max_val = max(draws)

	providedArgs = list(...)
	nbArgs = length(providedArgs)

	ls_names = names(providedArgs)

	val_ind = stri_detect(str = ls_names, regex = "val[[:digit:]]")
	xlab_ind = (ls_names == "xlab")
	ylab_ind = (ls_names == "ylab")
	main_ind = (ls_names == "main")
	label_ind = stri_detect(str = ls_names, regex = "label")
	iter_ind = stri_detect(str = ls_names, regex = "iter[[:digit:]]")

	scaling_ind = (ls_names == "scaling")
	if (any(scaling_ind)) scaling = providedArgs[["scaling"]] else scaling = 1

	if (any(label_ind))
		par(mar = c(5, 4, 4, 4))
	
	# Plot
	if (!is.null(filename))
	{
		pdf(paste0(filename, ifelse(!is.null(run), paste0("_", run), ""), ".pdf"))
		print(paste0("Figure saved under the name: ", filename, ifelse(!is.null(run), paste0("_", run), ""), ".pdf"))
	}
	
	plot(0, pch = "", xlim = c(0, n_iter), ylim = scaling*c(min_val, max_val), axes = TRUE, bg = "transparent",
		xlab = ifelse(any(xlab_ind), providedArgs[["xlab"]], ""),
		ylab = ifelse(any(ylab_ind), providedArgs[["ylab"]], ""),
		main = ifelse(any(main_ind), providedArgs[["main"]], ""))

	for (chain in 1:n_chains)
	{
		if (all(class(draws) %in% c("draws_array", "draws", "array")))
			lines(1:n_iter, scaling*draws[, chain, ], type = "l", col = colours_str[chain])
		if (is.array(draws) && !all(class(draws) %in% c("draws_array", "draws", "array")))
			lines(1:n_iter, scaling*draws[, chain], type = "l", col = colours_str[chain])
	}

	if (any(val_ind))
	{
		for (val in ls_names[val_ind])
			abline(h = scaling*providedArgs[[val]], col = "#CD212A", lwd = 4)
		
		if (any(label_ind))
		{
			num_vals = stri_sub(str = ls_names[val_ind], from = stri_locate(str = ls_names[val_ind], regex = "val")[, "end"] + 1)
			for (label in ls_names[label_ind])
			{
				num_label = stri_sub(str = label, from = stri_locate(str = label, regex = "label")[, "end"] + 1)
				corresponding_val = (ls_names[val_ind])[num_vals == num_label]
				axis(4, at = scaling*providedArgs[[corresponding_val]], providedArgs[[label]], las = 1)
			}
		}
	}

	if (any(iter_ind))
	{
		for (iter in ls_names[iter_ind])
			abline(v = providedArgs[[iter]], col = "#66666644", lwd = 0.2)
	}

	if (!is.null(filename))
		dev.off()
}

## Function to reshape draws_array
reshapeDraws = function(draws_array, id_latent, regex = "latent_dbh")
{
	id_latent = unique(id_latent)
	if (length(id_latent) != 1)
		stop("A single id should be provided")
	
	n_chains = ncol(draws_array)
	length_chain = nrow(draws_array)
	output = numeric(length = n_chains*length_chain)

	for (i in 1:n_chains)
	{
		start = (i - 1)*length_chain + 1
		end = i*length_chain
		output[start:end] = draws_array[, i, paste0(regex, "[", id_latent, "]")]
	}
	return(output)
}

## Function to plot the prior and posterior of a parameter
lazyPosterior = function(draws, fun = NULL, expand_bounds = FALSE, filename = NULL, run = NULL, multi = FALSE, ls_nfi = NULL, ...)
{
	# Dealing with draws as a list
	if (is.list(draws))
	{
		# --- Check-up
		nDraws = length(draws)
		len = data.table(nIter = integer(nDraws), nChains = integer(nDraws), nVariables = integer(nDraws), variableNames = character(nDraws))
		for (i in seq_along(draws))
		{
			if (!all(class(draws[[i]]) == c("draws_array", "draws", "array")))
				stop(paste0("draws[", i, "] is not an array extracted from a CmdStanMCMC object"))

			len[i, c("nIter", "nChains", "nVariables", "variableNames") := append(as.list(dim(draws[[i]])), summary(draws[[i]])[["variable"]])]
		}
		if (unique(len)[, .N] != 1)
			stop("Dimensions or variables' name mismatch within the provided draws")

		rm(len)
		# --- Format
		draws_unlist = posterior::bind_draws(draws[[1]], along = "iteration")
		for (j in 2:length(draws))
			draws_unlist = posterior::bind_draws(draws_unlist, draws[[i]], along = "iteration")
		draws = draws_unlist
		rm(draws_unlist)
	}
	
	# Check-up
	if (!all(class(draws) == c("draws_array", "draws", "array")))
		stop("Draws should be an array (a list) extracted from a CmdStanMCMC object (CmdStanMCMC objects)")

	
	if (!is.null(fun))
	{
		if (!isTRUE(all.equal(fun, dnorm)) &&
			!isTRUE(all.equal(fun, dlnorm)) &&
			!isTRUE(all.equal(fun, dgamma)) &&
			!isTRUE(all.equal(fun, dbeta))) # isFALSE will not work here, hence !isTRUE
		{
			stop("This function only accepts dnorm, dlnorm, dgamma, or dbeta as priors")
		}
	}

	# Get list of arguments
	providedArgs = list(...)
	ls_names = names(providedArgs)
	nbArgs = length(providedArgs)

	# Get the argument for density if provided
	n = 512
	n_ind = (ls_names == "n")
	if (any(n_ind))
	{
		n = providedArgs[["n"]]
		print(paste0("Using n = ", n, " for the density plot"))
	}

	# Get the parameter's name if provided
	params = ""
	params_ind = (ls_names == "params")
	if (any(params_ind))
		params = providedArgs[["params"]]

	# Get the index of the x-axis label
	xlab_ind = (ls_names == "xlab")

	# Get the indices of the x-axis limits
	min_x_ind = (ls_names == "min_x")
	max_x_ind = (ls_names == "max_x")

	# Get the scaling on the x-axis if provided
	scaling_ind = (ls_names == "scaling")
	if (any(scaling_ind)) scaling = providedArgs[["scaling"]] else scaling = 1

	# Get parameters for prior
	if (isTRUE(all.equal(fun, dnorm)))
	{
		if ((!all(c("mean", "sd") %in% names(providedArgs))) && (!all(c("arg1", "arg2") %in% names(providedArgs))))
			stop("You must provide mean and sd for dnorm")
		
		if (all(c("mean", "sd") %in% names(providedArgs)))
		{
			arg1 = providedArgs[["mean"]]
			arg2 = scaling*providedArgs[["sd"]]
		} else {
			arg1 = providedArgs[["arg1"]]
			arg2 = scaling*providedArgs[["arg2"]]
		}
	}

	if (isTRUE(all.equal(fun, dlnorm)))
	{
		if ((!all(c("mean", "sd") %in% names(providedArgs))) && (!all(c("arg1", "arg2") %in% names(providedArgs))) && 
			(!all(c("meanlog", "sdlog") %in% names(providedArgs))))
			stop("You must provide mean and sd or meanlog and sdlog for dlnorm")
		
		if (all(c("mean", "sd") %in% names(providedArgs)))
		{
			dlnorm_mean = providedArgs[["mean"]]
			dlnorm_sd = providedArgs[["sd"]]

			arg1 = log(dlnorm_mean^2/sqrt(dlnorm_sd^2 + dlnorm_mean^2)) + log(scaling)
			arg2 = sqrt(log(dlnorm_sd^2/dlnorm_mean^2 + 1))
		} else if (all(c("meanlog", "sdlog") %in% names(providedArgs))) {
			arg1 = providedArgs[["meanlog"]] + log(scaling)
			arg2 = providedArgs[["sdlog"]]
		} else {
			print("args 1 and 2 provided; it is assumed they are meanlog and sdlog")
			arg1 = providedArgs[["arg1"]] + log(scaling)
			arg2 = providedArgs[["arg2"]]
		}
	}

	if (isTRUE(all.equal(fun, dgamma)))
	{
		if ((!all(c("mean", "var") %in% names(providedArgs))) && (!all(c("shape", "rate") %in% names(providedArgs)))
			&& (!all(c("arg1", "arg2") %in% names(providedArgs))))
			stop("You must provide either mean and var or shape and rate for dgamma")
		
		if (all(c("mean", "var") %in% names(providedArgs)))
		{
			temp1 = providedArgs[["mean"]]
			temp2 = providedArgs[["var"]] # Squared because in this case it is a variance, not a std. dev.

			arg1 = temp1^2/temp2 # shape
			arg2 = temp1/(temp2*scaling) # rate
		}

		if (all(c("shape", "rate") %in% names(providedArgs)))
		{
			arg1 = providedArgs[["shape"]]
			arg2 = providedArgs[["rate"]]/scaling
		}

		if (all(c("arg1", "arg2") %in% names(providedArgs)))
		{
			print("args 1 and 2 provided; it is assumed they are shape and rate")
			arg1 = providedArgs[["arg1"]]
			arg2 = providedArgs[["arg2"]]/scaling
		}
	}

	if (isTRUE(all.equal(fun, dbeta)))
	{
		if ((!all(c("mean", "var") %in% names(providedArgs))) && (!all(c("shape1", "shape2") %in% names(providedArgs)))
			&& (!all(c("arg1", "arg2") %in% names(providedArgs))))
			stop("You must provide either mean and var or shape1 and shape2 for dbeta")

		if (scaling != 1)
			warning("I have not coded the scaling for the beta distribution. Your plot might be out of the window")
		
		if (all(c("mean", "var") %in% names(providedArgs)))
		{
			temp1 = providedArgs[["mean"]]
			temp2 = providedArgs[["var"]]

			arg1 = ((1 - temp1)/temp2 - 1/temp1)*temp1^2 # shape 1
			arg2 = arg1*(1/temp1 - 1) # shape 2
		}

		if (all(c("shape1", "shape2") %in% names(providedArgs)))
		{
			arg1 = providedArgs[["shape1"]]
			arg2 = providedArgs[["shape2"]]
		}

		if (all(c("arg1", "arg2") %in% names(providedArgs)))
		{
			print("args 1 and 2 provided; it is assumed they are shape1 and shape2")
			arg1 = providedArgs[["shape1"]]
			arg2 = providedArgs[["shape2"]]
		}

		max_y_prior = optimise(f = fun, interval = c(0, 1), maximum = TRUE, shape1 = arg1, shape2 = arg2)[["objective"]]
	}

	# Get posterior
	if (multi)
	{
		info = summary(draws)
		setDT(info)
		length_params = info[, .N]
		density_from_draws = vector(mode = "list", length = length_params)
		x = vector(mode = "list", length = length_params)
		y = vector(mode = "list", length = length_params)
		names(density_from_draws) = info[, variable]
		names(x) = info[, variable]
		names(y) = info[, variable]
		for (varName in info[, variable])
		{
			density_from_draws[[varName]] = density(scaling*draws[, , varName], n = n)
			x[[varName]] = density_from_draws[[varName]]$x
			y[[varName]] = density_from_draws[[varName]]$y
		}
		min_x = min(sapply(x, min))
		max_x = max(sapply(x, max))
		max_y = max(sapply(y, max))
	
	} else {
		density_from_draws = density(draws, n = n)
		x = density_from_draws$x
		y = density_from_draws$y
		min_x = min(x)
		max_x = max(x)
		max_y = max(y)
	}

	min_x = ifelse(min_x < 0, 1.1*min_x, 0.9*min_x) # To extend 10% from min_x
	max_x = ifelse(max_x < 0, 0.9*max_x, 1.1*max_x) # To extend 10% from max_x

	if (isTRUE(all.equal(fun, dnorm)))
	{
		max_y_prior = optimise(f = fun, interval = c(min_x, max_x), maximum = TRUE, mean = arg1, sd = arg2)[["objective"]]
		if (expand_bounds)
		{
			check_min_bound = integrate(fun, lower = ifelse(min_x < 0, 10*min_x, -10*min_x), upper = min_x, mean = arg1, sd = arg2,
				subdivisions = 2000, rel.tol = .Machine$double.eps^0.1)
			while (check_min_bound$value > 0.1)
			{
				min_x = ifelse(min_x < 0, 1.1*min_x, 0.9*min_x) # To extend 10% from min_x
				check_min_bound = integrate(fun, lower = ifelse(min_x < 0, 10*min_x, -10*min_x), upper = min_x, mean = arg1, sd = arg2,
					subdivisions = 2000, rel.tol = .Machine$double.eps^0.1)
			}

			check_max_bound = integrate(fun, lower = max_x, upper = ifelse(max_x < 0, -10*max_x, 10*max_x), mean = arg1, sd = arg2,
				subdivisions = 2000, rel.tol = .Machine$double.eps^0.1)
			while (check_max_bound$value > 0.1)
			{
				max_x = ifelse(max_x < 0, 0.9*max_x, 1.1*max_x) # To extend 10% from max_x
				check_max_bound = integrate(fun, lower = max_x, upper = ifelse(max_x < 0, -10*max_x, 10*max_x), mean = arg1, sd = arg2,
					subdivisions = 2000, rel.tol = .Machine$double.eps^0.1)
			}
		}
	}

	if (isTRUE(all.equal(fun, dlnorm)))
	{
		max_y_prior = optimise(f = fun, interval = c(min_x, max_x), maximum = TRUE, meanlog = arg1, sdlog = arg2)[["objective"]]
		if (expand_bounds)
		{
			check_min_bound = integrate(fun, lower = ifelse(min_x < 0, 10*min_x, -10*min_x), upper = min_x, meanlog = arg1,
				sdlog = arg2, subdivisions = 2000, rel.tol = .Machine$double.eps^0.1)
			while (check_min_bound$value > 0.1)
			{
				min_x = ifelse(min_x < 0, 1.1*min_x, 0.9*min_x) # To extend 10% from min_x
				check_min_bound = integrate(fun, lower = ifelse(min_x < 0, 10*min_x, -10*min_x), upper = min_x, meanlog = arg1,
					sdlog = arg2, subdivisions = 2000, rel.tol = .Machine$double.eps^0.1)
			}

			check_max_bound = integrate(fun, lower = max_x, upper = ifelse(max_x < 0, -10*max_x, 10*max_x), meanlog = arg1,
				sdlog = arg2, subdivisions = 2000, rel.tol = .Machine$double.eps^0.1)
			while (check_max_bound$value > 0.1)
			{
				max_x = ifelse(max_x < 0, 0.9*max_x, 1.1*max_x) # To extend 10% from max_x
				check_max_bound = integrate(fun, lower = max_x, upper = ifelse(max_x < 0, -10*max_x, 10*max_x), meanlog = arg1,
					sdlog = arg2, subdivisions = 2000, rel.tol = .Machine$double.eps^0.1)
			}
		}
	}

	if (isTRUE(all.equal(fun, dgamma)))
	{
		max_y_prior = optimise(f = fun, interval = c(min_x, max_x), maximum = TRUE, shape = arg1, rate = arg2)[["objective"]]
		if (expand_bounds)
		{
			check_min_bound = integrate(fun, lower = ifelse(min_x < 0, 10*min_x, -10*min_x), upper = min_x, shape = arg1, rate = arg2,
				subdivisions = 2000, rel.tol = .Machine$double.eps^0.1)
			while (check_min_bound$value > 0.1)
			{
				min_x = ifelse(min_x < 0, 1.1*min_x, 0.9*min_x) # To extend 10% from min_x
				check_min_bound = integrate(fun, lower = ifelse(min_x < 0, 10*min_x, -10*min_x), upper = min_x, shape = arg1, rate = arg2,
					subdivisions = 2000, rel.tol = .Machine$double.eps^0.1)
			}

			check_max_bound = integrate(fun, lower = max_x, upper = ifelse(max_x < 0, -10*max_x, 10*max_x), shape = arg1, rate = arg2,
				subdivisions = 2000, rel.tol = .Machine$double.eps^0.1)
			while (check_max_bound$value > 0.1)
			{
				max_x = ifelse(max_x < 0, 0.9*max_x, 1.1*max_x) # To extend 10% from max_x
				check_max_bound = integrate(fun, lower = max_x, upper = ifelse(max_x < 0, -10*max_x, 10*max_x), shape = arg1, rate = arg2,
					subdivisions = 2000, rel.tol = .Machine$double.eps^0.1)
			}
		}
	}
	if (!is.null(fun))
		max_y = max(max_y, max_y_prior)
	max_y = ifelse(max_y < 0, 0.9*max_y, 1.1*max_y) # To extend 10% from max_y

	# Plot
	if (!is.null(filename))
	{
		filename = paste0(filename, ifelse(!is.null(run), paste0("_", run), ""), ".pdf")
		pdf(filename)
		print(paste0("Figure saved under the name: ", filename))
	}

	if (any(min_x_ind))
		min_x = providedArgs[["min_x"]]
	if (any(max_x_ind))
		max_x = providedArgs[["max_x"]]
	
	# Plot posterior
	if (multi)
	{
		colours = MetBrewer::met.brewer("Hokusai3", length_params)
		colours_str = grDevices::colorRampPalette(colours)(length_params)
		colours_str_pol = paste0(colours_str, "66")
		plot(0, type = "n", xlim = c(min_x, max_x), ylim = c(0, max_y), ylab = "frequence", main = paste("Prior and posterior", params),
			xlab = ifelse(any(xlab_ind), providedArgs[["xlab"]], ""))
		for (i in 1:length_params)
		{
			lines(x = density_from_draws[[i]]$x, y = density_from_draws[[i]]$y, col = colours_str[i], lwd = 2)
			polygon(density_from_draws[[i]], col = colours_str_pol[i])
		}
	} else {
		plot(density_from_draws, xlim = c(min_x, max_x), col = "#295384", lwd = 2, main = paste("Prior and posterior", params))
		polygon(density_from_draws, col = "#29538466")
	}

	# Plot prior
	if (!is.null(fun))
	{
		curve(fun(x, arg1, arg2), add = TRUE, lwd = 2, col = "#F4C430")
		DescTools::Shade(fun(x, arg1, arg2), breaks = c(min_x, max_x), col = "#F4C43066", density = NA)
	}

	# Add legend
	if (multi && !is.null(ls_nfi))
		if (length(ls_nfi) != length_params)
			warning("Dimension mismatch between ls_nfi and length_params! The legend might not be correctly printed")

	if (!multi && !is.null(ls_nfi))
		if (length(ls_nfi) != 1)
			warning("To many NFI provided in ls_nfi! The legend might not be correctly printed")

	if (multi)
	{
		legend_text = ifelse(is.null(fun), paste("Posterior", if (!is.null(ls_nfi)) ls_nfi else 1:length_params),
			c("Prior", paste("Posterior", if (!is.null(ls_nfi)) ls_nfi else 1:length_params)))
		legend_colours = ifelse(is.null(fun), colours_str, c("#F4C430", colours_str))
		
		legend(x = "topright", legend = legend_text, fill = legend_colours, box.lwd = 0)
	} else {
		legend_text = ifelse(is.null(fun), paste("Posterior", ifelse(!is.null(ls_nfi), ls_nfi, "")),
			c("Prior", paste("Posterior", ifelse(!is.null(ls_nfi), ls_nfi, ""))))
		legend_colours = ifelse(is.null(fun), "#295384", c("#F4C430", "#295384"))

		legend(x = "topright", legend = legend_text, fill = legend_colours, box.lwd = 0)
	}

	if (!is.null(filename))
		dev.off()

	if (is.null(fun))
		return(list(arg1 = NA, arg2 = NA, min_x = min_x, max_x = max_x, max_y = max_y, max_y_prior = NA, filename = filename))
	
	return(list(arg1 = arg1, arg2 = arg2, min_x = min_x, max_x = max_x, max_y = max_y, max_y_prior = max_y_prior, filename = filename))
}

## Function to plot the posteriors of a parameter from a list of models
lazyComparePosterior = function(draws_ls, filename = NULL, run = NULL, multi_nfi = FALSE, ls_nfi = NULL, ...)
{
	# Check-up
	if (!is.list(draws_ls))
		stop("Draws should be a list of arrays extracted from a CmdStanMCMC object")

	nDraws = length(draws_ls)
	len = data.table(nIter = integer(nDraws), nChains = integer(nDraws), nVariables = integer(nDraws))
	for (i in seq_along(draws_ls))
	{
		if (!all(class(draws_ls[[i]]) == c("draws_array", "draws", "array")))
			stop(paste0("draws_ls[", i, "] is not an array extracted from a CmdStanMCMC object"))

		len[i, c("nIter", "nChains", "nVariables") := as.list(dim(draws_ls[[i]]))]
	}
	if (unique(len)[, .N] != 1)
		stop("Dimensions mismatch within the provided draws")

	# Get list of arguments
	providedArgs = list(...)
	ls_names = names(providedArgs)
	nbArgs = length(providedArgs)

	# Get the argument for density if provided
	n = 512
	n_ind = (ls_names == "n")
	if (any(n_ind))
	{
		n = providedArgs[["n"]]
		print(paste0("Using n = ", n, " for the density plot"))
	}

	# Get the parameter's name if provided
	params = ""
	params_ind = (ls_names == "params")
	if (any(params_ind))
		params = providedArgs[["params"]]

	# Get the index of the x-axis label
	xlab_ind = (ls_names == "xlab")

	# Get the indices of the x-axis limits
	min_x_ind = (ls_names == "min_x")
	max_x_ind = (ls_names == "max_x")

	# Get the index of the legend text
	legend_ind = (ls_names == "legend")

	# Create and fill list of posteriors
	density_ls = vector(mode = "list", length = nDraws)
	
	min_x = +Inf
	max_x = -Inf
	max_y = -Inf

	for (i in seq_along(draws_ls))
	{
		# --- get posterior
		if (multi_nfi)
		{
			info = summary(draws_ls[[i]])
			setDT(info)
			length_params = info[, .N]
			density_ls[[i]] = vector(mode = "list", length = length_params)
			x = vector(mode = "list", length = length_params)
			y = vector(mode = "list", length = length_params)
			names(density_ls[[i]]) = info[, variable]
			names(x) = info[, variable]
			names(y) = info[, variable]
			for (varName in info[, variable])
			{
				density_ls[[i]][[varName]] = density(draws_ls[[i]][, , varName], n = n)
				x[[varName]] = density_ls[[i]][[varName]]$x
				y[[varName]] = density_ls[[i]][[varName]]$y
			}
			temporary_min_x = min(sapply(x, min))
			temporary_max_x = max(sapply(x, max))
			temporary_max_y = max(sapply(y, max))
		} else {
			density_ls[[i]] = density(draws_ls[[i]], n = n)
			x = density_ls[[i]]$x
			y = density_ls[[i]]$y
			temporary_min_x = min(x)
			temporary_max_x = max(x)
			temporary_max_y = max(y)
		}
		
		if (temporary_min_x < min_x)
			min_x = temporary_min_x
		if (temporary_max_x > max_x)
			max_x = temporary_max_x
		if (temporary_max_y > max_y)
			max_y = temporary_max_y
	}

	min_x = ifelse(min_x < 0, 1.01*min_x, 0.99*min_x) # To extend by 1% from min_x
	max_x = ifelse(max_x < 0, 0.99*max_x, 1.01*max_x) # To extend by 1% from max_x

	if (any(min_x_ind))
		min_x = providedArgs[["min_x"]]
	if (any(max_x_ind))
		max_x = providedArgs[["max_x"]]

	max_y = ifelse(max_y < 0, 0.99*max_y, 1.01*max_y) # To extend by 1% from max_y

	names(density_ls) = paste("draw", 1:nDraws, sep = "_")

	# Open file if plot printed in a pdf
	if (!is.null(filename))
	{
		filename = paste0(filename, ifelse(!is.null(run), paste0("_", run), ""), ".pdf")
		pdf(filename)
		print(paste0("Figure saved under the name: ", filename))
	}
	
	# Plot posterior
	# --- Prepare the posteriors colour
	nbPosteriors = ifelse(multi_nfi, length_params*nDraws, nDraws)

	colours = MetBrewer::met.brewer("Austria", nbPosteriors)
	colours_str = grDevices::colorRampPalette(colours)(nbPosteriors)
	colours_str_pol = paste0(colours_str, "66")

	counterColour = 1
	plot(0, type = "n", xlim = c(min_x, max_x), ylim = c(0, max_y), ylab = "frequence", main = paste("Posteriors", params),
		xlab = ifelse(any(xlab_ind), providedArgs[["xlab"]], ""))

	for (i in seq_along(draws_ls))
	{
		if (multi_nfi)
		{
			for (j in 1:length_params)
			{
				lines(x = density_ls[[i]][[j]]$x, y = density_ls[[i]][[j]]$y, col = colours_str[counterColour], lwd = 4, lty = i)
				polygon(density_ls[[i]][[j]], col = colours_str_pol[counterColour])
				counterColour = counterColour + 1
			}
		} else {
			lines(density_ls[[i]], col = colours_str[counterColour], lwd = 4, lty = i)
			polygon(density_ls[[i]], col = colours_str_pol[counterColour])
			counterColour = counterColour + 1
		}
	}

	# Add legend
	if (multi_nfi && !is.null(ls_nfi))
		if (length(ls_nfi) != length_params)
			warning("Dimension mismatch between ls_nfi and length_params! The legend might not be correctly printed")

	if (!multi_nfi && !is.null(ls_nfi))
		if (length(ls_nfi) != 1)
			warning("To many NFI provided in ls_nfi! The legend might not be correctly printed")

	if (multi_nfi)
	{
		posterior_num = paste("Posterior", 1:nDraws)
		posterior_country = if (!is.null(ls_nfi)) ls_nfi else 1:length_params
		legend_text = CJ(posterior_num, posterior_country, sorted = FALSE)[, paste(posterior_num, posterior_country, sep = " ")]
		legend_colours = colours_str
		
		legend(x = "topright", legend = legend_text, col = legend_colours, lty = rep(1:nDraws, each = length_params), lwd = 2, box.lwd = 0)
	} else {
		if (!any(legend_ind))
		{
			posterior_num = paste("Posterior", 1:nDraws)
			posterior_country = if (!is.null(ls_nfi)) ls_nfi else ""
			legend_text = CJ(posterior_num, posterior_country, sorted = FALSE)[, paste(posterior_num, posterior_country, sep = " ")]
		} else {
			legend_text = providedArgs[["legend"]]
		}
		legend_colours = colours_str_pol

		legend(x = "topright", legend = legend_text, fill = legend_colours, box.lwd = 0)
	}

	if (!is.null(filename))
		dev.off()
	
	return(list(min_x = min_x, max_x = max_x, max_y = max_y, filename = filename))
}

## Function to expand the basic names when there is more than one NFI
expand = function(base_names, nb_nfi, patterns = c("Obs", "proba"))
{
	if (nb_nfi < 1)
		stop("Nothing to expand")
	
	new_names = vector(mode = "list", length = length(patterns))
	old_names = base_names
	for (i in seq_along(patterns))
	{
		reg = patterns[i]
		toModify = base_names[stri_detect(base_names, regex = reg)]
		base_names = base_names[!stri_detect(base_names, regex = reg)]
		new_names[[i]] = character(length = nb_nfi*length(toModify))
		for (j in seq_along(toModify))
			new_names[[i]][((j - 1)*nb_nfi + 1):(j*nb_nfi)] = paste0(toModify[j], "[", 1:nb_nfi, "]")
	}

	combined_names = c(base_names, unlist(new_names))
	return(list(old_names = old_names, new_names = combined_names))
}

## Function to do a pair plot of parameters versus energy
energyPairs = function(path, run, results, nb_nfi, energy, rm_names = c("latent", "Effect"), n_rows = 3, n_cols = 6, filename = "pairs.pdf")
{
	if (!is.null(filename))
		filename = paste0(path, ifelse(!is.null(run), paste0(run, "_"), run), "pairs.pdf")

	params_names = results$metadata()$stan_variables

	for (i in seq_along(rm_names))
		params_names = params_names[!stri_detect(params_names, regex = rm_names[i])]
	
	if (nb_nfi > 1)
		params_names = expand(params_names, nb_nfi)[["new_names"]]

	if (length(params_names) > n_rows*n_cols)
		warning("Not enough rows or cols for the number of provided parameters")
	
	if (!is.null(filename))
		pdf(filename, height = 10, width = 10)
	
	par(mfrow = c(n_rows, n_cols))

	length_params = length(params_names)
	correl_energy = data.table(parameters = params_names, correlation_energy = numeric(length_params))

	for (i in 1:length_params)
	{
		smoothScatter(x = energy, y = as.vector(results$draws(params_names[i])), ylab = params_names[i])
		correl_energy[i, correlation_energy := cor(energy, as.vector(results$draws(params_names[i])))]
	}

	if (!is.null(filename))
	{
		dev.off()
		print(paste("Figure saved under the name:", filename))
	}

	return(correl_energy)
}

## Detect if a species has been processed or not
isProcessed = function(path, multi, lim_time, begin = "^growth-", extension = ".rds$", format = "ymd", lower = 1, upper = 4)
{
	if (class(lim_time) != "Date")
		lim_time = as.Date(lim_time)
	run_vec = lower:upper
	n_runs = length(run_vec)
	processed = rep(FALSE, n_runs)

	if (!dir.exists(path))
		return(FALSE)

	if (multi)
	{
		for (i in 1:n_runs)
		{
			run = run_vec[i]
			date_run = getLastRun(path, begin = begin, extension = extension, format = format, run = i)[["time_ended"]]
			date_run = as.Date(date_run)
			if (!is.na(date_run) && (date_run > lim_time))
				processed[i] = TRUE
		}
	} else {
		date_run = getLastRun(path, begin = begin, extension = extension, format = format, run = 1)[["time_ended"]]
		date_run = as.Date(date_run)
		if (!is.na(date_run) && (date_run > lim_time))
			processed = TRUE
	}
	return(all(processed))
}

## Wrapping function to call all the other plot functions and to gather informations on the runs
centralised_fct = function(species, multi, n_runs, ls_nfi, params_dt, run = NULL, isDBH_normalised = TRUE, simulatePosterior = TRUE)
{
	path = paste0("./", species, "/")
	n_nfi = length(ls_nfi)
	error_dt = data.table(nfi = rep(c(ls_nfi, "all")), sigmaProc = numeric(n_nfi + 1),
		etaObs = numeric(n_nfi + 1), proba = numeric(n_nfi + 1), correl_eta_proba = numeric(n_nfi + 1))
	setkey(error_dt, nfi)
	
	if (multi && !is.null(run))
	{
		print(paste0("Run = ", run, "; multi and n_runs parameters ignored"))
		temporary = centralised_fct(species, FALSE, n_runs, ls_nfi, params_dt, run, isDBH_normalised, simulatePosterior) # Recursive call
		error_dt = temporary[["error_dt"]]
		correl_energy = temporary[["correl_energy"]]
	} else if (multi && is.null(run)) {
		error_ls = vector(mode = "list", length = n_runs)
		correl_ls = vector(mode = "list", length = n_runs)
		for (i in 1:n_runs)
		{
			temporary = centralised_fct(species, FALSE, n_runs, ls_nfi, params_dt, i, isDBH_normalised, simulatePosterior) # Recursive call
			error_ls[[i]] = temporary[["error_dt"]]
			correl_ls[[i]] = temporary[["correl_energy"]]
		}
		error_dt = rbindlist(error_ls) # , idcol = "run_id"
		correl_energy = rbindlist(correl_ls) # , idcol = "run_id"
	} else {
		# Get inf last run
		info_lastRun = getLastRun(path = path, run = run)
		lastRun = info_lastRun[["file"]]
		time_ended = info_lastRun[["time_ended"]]

		# Load dbh standardising data if necessary
		sd_dbh = 1
		if (isDBH_normalised)
		{
			norm_dbh_dt = readRDS(paste0(path, ifelse(is.null(run), "", paste0(run, "_")), "dbh_normalisation.rds"))
			sd_dbh = norm_dbh_dt[, sd]
		}

		# Load results and associated data set
		results = readRDS(paste0(path, lastRun))

		results$print(c("lp__", params_dt[, parameters], "etaObs", "proba", "sigmaProc"), max_rows = 20)

		Sys.sleep(5)

		## Pairs plot of parameters versus energy
		# Extract energy 
		energy = as.vector(results$sampler_diagnostics(inc_warmup = FALSE)[, , "energy__"])

		# Plot
		correl_energy = energyPairs(path, run = run, results, nb_nfi = n_nfi, energy)

		## Plot prior and posterior for error terms
		# For process error (sigmaProc), it is a variance (of a gamma distrib)
		sigmaProc_array = results$draws("sigmaProc")
		lazyPosterior(draws = sigmaProc_array, fun = dlnorm, filename = paste0(path, "sigmaProc_posterior"), params = "process error",
			meanlog = log(1.28) - log(sd_dbh), sdlog = 0.16, run = run, expand_bounds = TRUE)

		lazyTrace(draws = sigmaProc_array, filename = paste0(path, "sigmaProc_traces"), run = run)

		error_dt["all", sigmaProc := sd_dbh*sqrt(mean(sigmaProc_array))]

		# For measurement error:
		# --- Common variable
		multi_NFI = if (n_nfi > 1) TRUE else FALSE

		# --- Extreme error (etaObs), it is a sd (of a normal distrib)...
		etaObs_array = results$draws("etaObs")
		lazyPosterior(draws = etaObs_array, fun = dgamma, filename = paste0(path, "etaObs_posterior"), run = run, xlab = "Error in mm",
			shape = 30^2/45.0, rate = sd_dbh*30/45.0, params = "extreme obs error", multi = multi_NFI, scaling = sd_dbh,
			ls_nfi = ls_nfi, expand_bounds = TRUE)

		# --- ... and its associated probability of occurrence
		proba_array = results$draws("proba")
		lazyPosterior(draws = proba_array, fun = dbeta, filename = paste0(path, "proba_posterior"), run = run, xlab = "Probability",
			shape1 = 48.67, shape2 = 1714.84, params = "probability extreme obs error", multi = multi_NFI,
			ls_nfi = ls_nfi)
		
		for (i in 1:n_nfi)
		{
			lazyTrace(draws = results$draws(paste0("etaObs[", i, "]"), inc_warmup = FALSE),
				filename = paste0(path, "etaObs[", i, "]_traces"), run = run)
			lazyTrace(draws = results$draws(paste0("proba[", i, "]"), inc_warmup = FALSE),
				filename = paste0(path, "proba[", i, "]_traces"), run = run)
		}

		error_dt["all", etaObs := sd_dbh*mean(etaObs_array)]
		error_dt["all", proba := mean(proba_array)]
		error_dt["all", correl_eta_proba := cor(etaObs_array, proba_array)]

		count = 0

		for (nfi in ls_nfi)
		{
			count = count + 1
			etaObs_array = results$draws(paste0("etaObs[", count, "]"))
			proba_array = results$draws(paste0("proba[", count, "]"))

			error_dt[nfi, sigmaProc := NA]
			error_dt[nfi, etaObs := mean(etaObs_array)]
			error_dt[nfi, proba := mean(proba_array)]
			error_dt[nfi, correl_eta_proba := cor(etaObs_array, proba_array)]
		}

		## Plot prior and posterior for main parameters (i.e., slopes and random effects, not the errors nor proba)
		for (param in params_dt[, parameters])
		{
			lazyPosterior(draws = results$draws(param, inc_warmup = FALSE), fun = params_dt[param, priors][[1]], run = run,
				expand_bounds = params_dt[param, expand_bounds], filename = paste0(path, param, "_posterior"),
				params = params_dt[param, title], arg1 = params_dt[param, arg1], arg2 = params_dt[param, arg2])

			lazyTrace(draws = results$draws(param, inc_warmup = FALSE), filename = paste0(path, param, "_traces"), run = run)
		}

		## Add run id to data tables
		error_dt[, run_id := run]
		correl_energy[, run_id := run]

		output = list(error_dt = error_dt, correl_energy = correl_energy, fileResults = paste0(path, lastRun))

		## Posterior predictive checking: Can the model give rise to new observations that properly resemble the original data?
		if (simulatePosterior)
		{
			# Compile simulation generator
			gq_model = cmdstan_model("./generate_posteriorSimulations.stan")

			# Load data
			stanData = readRDS(paste0(path, ifelse(!is.null(run), paste0(run, "_"), run), "stanData.rds"))
			indices = readRDS(paste0(path, ifelse(!is.null(run), paste0(run, "_"), run), "indices.rds"))

			# Access data
			n_chains = results$num_chains()
			iter_sampling = results$metadata()$iter_sampling
			n_obs = stanData$n_obs
			n_hiddenState = stanData$n_latentGrowth + stanData$n_indiv

			stanData$nfi_id = unique(indices[, .(plot_id, tree_id, nfi_index)])[, nfi_index]

			if (length(stanData$nfi_id) != stanData$n_indiv)
				stop("Dimensions mismatch")

			# Simulations
			generate_quantities = gq_model$generate_quantities(results$draws(), data = stanData, parallel_chains = n_chains)

			output = append(output, list(posteriorSim = list(posterior_draws = generate_quantities,
				info = list(run = run, species = species, path = path, n_chains = n_chains, iter_sampling = iter_sampling,
					n_obs = n_obs, n_indiv = stanData$n_indiv, n_hiddenState = n_hiddenState),
				parents_index = stanData$parents_index, children_index = stanData$children_index,
				last_child_index = stanData$last_child_index,
				divergences = which(results$sampler_diagnostics()[, , "divergent__"] == 1))))
		} else {
			stanData = readRDS(paste0(path, ifelse(!is.null(run), paste0(run, "_"), run), "stanData.rds"))
		}

		pr_q25 = quantile(stanData$precip)["25%"]
		pr_q75 = quantile(stanData$precip)["75%"]
		tas_q25 = quantile(stanData$tas)["25%"]
		tas_q75 = quantile(stanData$tas)["75%"]
		ph_q25 = quantile(stanData$ph)["25%"]
		ph_q75 = quantile(stanData$ph)["75%"]
		ba_q25 = quantile(stanData$standBasalArea)["25%"]
		ba_q75 = quantile(stanData$standBasalArea)["75%"]

		scaling = data.table(variable = c("pr", "tas", "ph", "standBasalArea_interp"),
			mu = c(stanData$pr_mu, stanData$tas_mu, stanData$ph_mu, stanData$ba_mu),
			sd = c(stanData$pr_sd, stanData$tas_sd, stanData$ph_sd, stanData$ba_sd))

		params = getParams(results, c("averageGrowth", "dbh_slope", "dbh_slope2", "pr_slope", "tas_slope", "ph_slope", "competition_slope",
			"pr_slope2", "tas_slope2", "ph_slope2", "sigmaProc"))

		
		pdf(paste0(path, "growth_curve.pdf"))
		par(mar = c(5, 4, 4, 10), xpd = TRUE)
		# Empty plot
		# --- Bounds for x-axis
		v = seq(20, 3520, by = 50)
		dbh_min = min(stanData[["dbh_init"]])
		dbh_max = max(stanData[["dbh_init"]])

		if ((dbh_min < 50) || (dbh_max > 3000))
			stop("dbh range out of bounds 50 and 3500")

		x_min = v[min(which(abs(dbh_min - v) == min(abs(dbh_min - v))))]
		x_max = v[max(which(abs(dbh_max - v) == min(abs(dbh_max - v))))]

		# --- Bounds for y-axis
		y_min = min(
			optimize(growth_fct, interval = c(x_min, x_max), tol = 1e-4, maximum = FALSE, pr = pr_q25, tas = tas_q25, ph = ph_q25,
				basalArea = ba_q25, params = params, sd_dbh = sd_dbh, standardised_dbh = FALSE, scaling = scaling)$objective,
			optimize(growth_fct, interval = c(x_min, x_max), tol = 1e-4, maximum = FALSE, pr = pr_q25, tas = tas_q75, ph = ph_q25,
				basalArea = ba_q25, params = params, sd_dbh = sd_dbh, standardised_dbh = FALSE, scaling = scaling)$objective,
			optimize(growth_fct, interval = c(x_min, x_max), tol = 1e-4, maximum = FALSE, pr = pr_q75, tas = tas_q25, ph = ph_q25,
				basalArea = ba_q25, params = params, sd_dbh = sd_dbh, standardised_dbh = FALSE, scaling = scaling)$objective,
			optimize(growth_fct, interval = c(x_min, x_max), tol = 1e-4, maximum = FALSE, pr = pr_q75, tas = tas_q75, ph = ph_q25,
				basalArea = ba_q25, params = params, sd_dbh = sd_dbh, standardised_dbh = FALSE, scaling = scaling)$objective)

		y_max = max(
			optimize(growth_fct, interval = c(x_min, x_max), tol = 1e-4, maximum = TRUE, pr = pr_q25, tas = tas_q25, ph = ph_q25,
				basalArea = ba_q25, params = params, sd_dbh = sd_dbh, standardised_dbh = FALSE, scaling = scaling)$objective,
			optimize(growth_fct, interval = c(x_min, x_max), tol = 1e-4, maximum = TRUE, pr = pr_q25, tas = tas_q75, ph = ph_q25,
				basalArea = ba_q25, params = params, sd_dbh = sd_dbh, standardised_dbh = FALSE, scaling = scaling)$objective,
			optimize(growth_fct, interval = c(x_min, x_max), tol = 1e-4, maximum = TRUE, pr = pr_q75, tas = tas_q25, ph = ph_q25,
				basalArea = ba_q25, params = params, sd_dbh = sd_dbh, standardised_dbh = FALSE, scaling = scaling)$objective,
			optimize(growth_fct, interval = c(x_min, x_max), tol = 1e-4, maximum = TRUE, pr = pr_q75, tas = tas_q75, ph = ph_q25,
				basalArea = ba_q25, params = params, sd_dbh = sd_dbh, standardised_dbh = FALSE, scaling = scaling)$objective)

		plot(0, type = "n", xlab = "dbh (in mm)", ylab = "Growth (in mm/yr)", xlim = c(x_min, x_max), ylim = c(y_min, y_max))

		# Plot curves
		curve(
			growth_fct(x, pr_q25, tas_q25, ph_q25, ba_q25, params, sd_dbh, standardised_dbh = FALSE, scaling = scaling),
				from = x_min, to = x_max, lwd = 2, lty = 2, col = "#34568B", add = TRUE)
		
		curve(
			growth_fct(x, pr_q25, tas_q75, ph_q25, ba_q25, params, sd_dbh, scaling = scaling, standardised_dbh = FALSE),
				from = x_min, to = x_max, lwd = 2, lty = 2, col = "#CD212A", add = TRUE)
		
		curve(
			growth_fct(x, pr_q75, tas_q25, ph_q25, ba_q25, params, sd_dbh, scaling = scaling, standardised_dbh = FALSE),
				from = x_min, to = x_max, lwd = 2, col = "#34568B", add = TRUE)
		
		curve(
			growth_fct(x, pr_q75, tas_q75, ph_q25, ba_q25, params, sd_dbh, scaling = scaling, standardised_dbh = FALSE),
				from = x_min, to = x_max, lwd = 2, col = "#CD212A", add = TRUE)
		
		legend(x = "topright", inset = c(-0.45, 0), legend = c("P 25 and T 25", "P 25 and T 75", "P 75 and T 25", "P 75 and T 75"),
			lty = c(2, 2, 1, 1), col = c("#34568B", "#CD212A", "#34568B", "#CD212A"), lwd = 2, bty = "n")
		dev.off()
	}
	return(output)
}

## Function to plot the correlations energy <--> parameters for each species, and to plot rescaled error values
plot_correl_error = function(error_dt, correl_dt, threshold_correl = 0.1, rm_correl = "lp__")
{
	correl_dt = correl_dt[!(parameters %in% rm_correl)]
	
	ls_species = correl_dt[, unique(speciesName_sci)] # Should be the same species in error

	for (species in ls_species)
	{
		path = paste0("./", species, "/")
		current_correl = correl_dt[speciesName_sci == species]
		ls_runs = current_correl[speciesName_sci == species, unique(run_id)]
		species_runs = length(ls_runs)
		ls_params = current_correl[speciesName_sci == species, unique(parameters)]
		nb_params = length(ls_params)

		# Plot correlations parameters versus energy
		pdf(paste0(path, "correlations_energy.pdf"), height = 10, width = 10)
		par(mar = c(5, 10, 0, 0))
		plot(0, type = "n", xlim = c(-1, 1), ylim = c(0, nb_params + 1), ylab = "", xlab = "Correlation with energy",
			axes = FALSE, xaxt = "n", yaxt = "n")

		param_counter = 1
		for (current_param in ls_params)
		{
			mean_value = current_correl[parameters == current_param, mean(correlation_energy)]
			# "#72BCD5"
			segments(x0 = 0, y0 = param_counter, x1 = mean_value, y1 = param_counter, lty = 1, lwd = 2,
				col = if (abs(mean_value) > threshold_correl) "#EF8A47" else "#34568B")
			points(mean_value, y = param_counter, pch = 15, cex = 1,
				col = if (abs(mean_value) > threshold_correl) "#EF8A47" else "#34568B")
			run_counter = 1
			if (species_runs %% 2 == 0) # Note that since species_runs > 0, this also implies that species_runs > 1
			{
				intercept_vec = seq(-species_runs/2, species_runs/2, by = 1)
				intercept_vec = intercept_vec[intercept_vec != 0]
				for (i in intercept_vec)
				{
					value = current_correl[parameters == current_param & run_id == run_counter, correlation_energy]
					intercept = param_counter + 0.1*i
					segments(x0 = 0, y0 = intercept, x1 = value, y1 = intercept, lty = 2, lwd = 0.75,
						col = if (abs(value) > threshold_correl) "#EF8A47" else "#34568B")
					points(value, y = intercept, pch = 20, cex = 0.75,
						col = if (abs(value) > threshold_correl) "#EF8A47" else "#34568B")
					run_counter = run_counter + 1
				}
			}
			param_counter = param_counter + 1
		}
		x = c(-threshold_correl, threshold_correl)
		y = c(nb_params + species_runs/2*0.1, nb_params + species_runs/2*0.1)
		lines(rep(x, each = 3), t(matrix(c(y, rep(c(par()$usr[3], NA), each = 2)), ncol = 3)), lwd = 0.5, lty = "dashed")
		lines(rep(0, each = 3), t(matrix(c(nb_params + species_runs/2*0.1, rep(c(par()$usr[3], NA), each = 1)), ncol = 3)), lwd = 2)
		axis(side = 1, at = c(-1, -0.5, -threshold_correl, 0, threshold_correl, 0.5, 1))
		axis(side = 2, at = 1:nb_params, labels = ls_params, las = 1)
		dev.off()

		# Plot correlations among errors and proba
		current_error = error_dt[speciesName_sci == species]
		ls_cols = c("correl_eta_proba")
		ls_nfi = current_error[nfi != "all", unique(nfi)]
		n_nfi = length(ls_nfi)
		col_counter = 1
		pdf(paste0(path, "correlations_errors_proba.pdf"), height = 10, width = 10)
		if (n_nfi > 1)
		{
			layout(mat = matrix(c(1, 2), nrow = 1, ncol = 2))
			par(mar = c(5, 10, 0, 0))
			plot(0, type = "n", xlim = c(-1, 1), ylim = c(0, length(ls_cols)*n_nfi + 1), ylab = "", xlab = "Correlation",
				axes = FALSE, xaxt = "n", yaxt = "n")
			current_col = ls_cols[1]
			for (current_col in ls_cols)
			{
				for (nfi_id in 1:n_nfi)
				{
					mean_value = mean(unlist(current_error[nfi == ls_nfi[nfi_id], ..current_col]))
					segments(x0 = 0, y0 = col_counter, x1 = mean_value, y1 = col_counter, lty = 1, lwd = 2,
						col = if (abs(mean_value) > threshold_correl) "#EF8A47" else "#34568B")
					points(mean_value, y = col_counter, pch = 15, cex = 1,
						col = if (abs(mean_value) > threshold_correl) "#EF8A47" else "#34568B")
					run_counter = 1
					if (species_runs %% 2 == 0) # Note that this since species_runs > 0, it also implies species_runs > 1 in this case
					{
						intercept_vec = seq(-species_runs/2, species_runs/2, by = 1)
						intercept_vec = intercept_vec[intercept_vec != 0]
						for (i in intercept_vec)
						{
							value = unlist(current_error[nfi == ls_nfi[nfi_id] & run_id == run_counter, ..current_col])
							intercept = col_counter + 0.1*i
							segments(x0 = 0, y0 = intercept, x1 = value, y1 = intercept, lty = 2, lwd = 0.75,
								col = if (abs(value) > threshold_correl) "#EF8A47" else "#34568B")
							points(value, y = intercept, pch = 20, cex = 0.75,
								col = if (abs(value) > threshold_correl) "#EF8A47" else "#34568B")
							run_counter = run_counter + 1
						}
					}
					col_counter = col_counter + 1
				}
			}
			x = c(-threshold_correl, threshold_correl)
			y = c(length(ls_cols)*n_nfi, length(ls_cols)*n_nfi) + species_runs/2*0.1
			lines(rep(x, each = 3), t(matrix(c(y, rep(c(par()$usr[3], NA), each = 2)), ncol = 3)), lwd = 0.5, lty = "dashed")
			lines(rep(0, each = 3), t(matrix(c(length(ls_cols)*n_nfi + species_runs/2*0.1,
				rep(c(par()$usr[3], NA), each = 1)), ncol = 3)), lwd = 2)
			axis(side = 1, at = c(-1, -0.5, -threshold_correl, 0, threshold_correl, 0.5, 1))

			y_labels = expand.grid(c("sigma - eta", "sigma - proba", "eta - proba"), ls_nfi, stringsAsFactors = FALSE)
			setDT(y_labels)
			setorder(y_labels)
			order_according_cols = c((n_nfi + 1):(2*n_nfi), (2*n_nfi + 1):(3*n_nfi), 1:n_nfi)
			axis(side = 2, at = 1:(length(ls_cols)*n_nfi), las = 1,
				labels = do.call(paste, y_labels[order_according_cols]))
		}
		col_counter = 1
		par(mar = c(5, 10, 2, 0))
		plot(0, type = "n", xlim = c(-1, 1), ylim = c(0, length(ls_cols)*n_nfi + 1), ylab = "", xlab = "Correlation",
			axes = FALSE, xaxt = "n", yaxt = "n")
		current_col = ls_cols[1]
		for (current_col in ls_cols)
		{
			mean_value = mean(unlist(current_error[nfi == "all", ..current_col]))
			segments(x0 = 0, y0 = 1.5*col_counter, x1 = mean_value, y1 = 1.5*col_counter, lty = 1, lwd = 2,
				col = if (abs(mean_value) > threshold_correl) "#EF8A47" else "#34568B")
			points(mean_value, y = 1.5*col_counter, pch = 15, cex = 1,
				col = if (abs(mean_value) > threshold_correl) "#EF8A47" else "#34568B")
			run_counter = 1
			if (species_runs %% 2 == 0) # Note that this since species_runs > 0, it also implies species_runs > 1 in this case
			{
				intercept_vec = seq(-species_runs/2, species_runs/2, by = 1)
				intercept_vec = intercept_vec[intercept_vec != 0]
				for (i in intercept_vec)
				{
					value = unlist(current_error[nfi == "all" & run_id == run_counter, ..current_col])
					intercept = 1.5*col_counter + 0.1*i
					segments(x0 = 0, y0 = intercept, x1 = value, y1 = intercept, lty = 2, lwd = 0.75,
						col = if (abs(value) > threshold_correl) "#EF8A47" else "#34568B")
					points(value, y = intercept, pch = 20, cex = 0.75,
						col = if (abs(value) > threshold_correl) "#EF8A47" else "#34568B")
					run_counter = run_counter + 1
				}
			}
			col_counter = col_counter + 1
		}
		x = c(-threshold_correl, threshold_correl)
		y = c(length(ls_cols)*n_nfi, length(ls_cols)*n_nfi) + species_runs/2*0.1
		lines(rep(x, each = 3), t(matrix(c(y, rep(c(par()$usr[3], NA), each = 2)), ncol = 3)), lwd = 0.5, lty = "dashed")
		lines(rep(0, each = 3), t(matrix(c(length(ls_cols)*n_nfi + species_runs/2*0.1,
			rep(c(par()$usr[3], NA), each = 1)), ncol = 3)), lwd = 2)
		axis(side = 1, at = c(-1, -0.5, -threshold_correl, 0, threshold_correl, 0.5, 1))
		axis(side = 2, at = 1.5*1:3, las = 1,
			labels = c("sigma - eta", "sigma - proba", "eta - proba"))

		dev.off()
		print(paste(species, "done"))
	}
}

## Function to check if plotting one parameter against others shows some funnel structures
checkFunnels = function(results, param, nb_nfi, rm_names = c("latent", "Effect", "lp__"), n_rows = 3, n_cols = 6, filename = NULL)
{
	params_names = results$metadata()$stan_variables
	
	for (i in seq_along(rm_names))
		params_names = params_names[!stri_detect(params_names, regex = rm_names[i])]

	if (nb_nfi > 1)
		params_names = expand(params_names, nb_nfi)[["new_names"]]
	
	params_names = params_names[params_names != param]
	length_params = length(params_names)
	if (length(params_names) > n_rows*n_cols)
		warning("Not enough rows or cols for the number of provided parameters")

	divergences = which(results$sampler_diagnostics()[, , "divergent__"] == 1)

	if (!is.null(filename))
		pdf(filename, height = 10, width = 10)
	
	par(mfrow = c(n_rows, n_cols))

	for (i in 1:length_params)
	{
		x_array = results$draws(params_names[i])
		y_array = results$draws(param)
		smoothScatter(x = x_array, y = y_array, xlab = params_names[i], ylab = param, pch = 16)

		points(as.vector(x_array)[divergences], as.vector(y_array)[divergences],
			col = "#EF8A47", pch = 16)
	}

	if (!is.null(filename))
		dev.off()
}

## Function to plot latent dbh states time series (posteriorSim is generated by the centralised function)
dbh_timeSeries = function(posteriorSim, plotMean = TRUE, filename = NULL, rescale = TRUE, ...)
{
	names_posteriorSim = c("posterior_draws", "info", "parents_index", "children_index", "last_child_index", "divergences")
	if (!all(names(posteriorSim) %in% names_posteriorSim))
		stop(paste("Simulated posterior must contain the following:", paste(names_posteriorSim, collapse = "\n- "), sep = "\n- "))

	if (!is.list(posteriorSim))
		stop("Simulated posterior must be a list")

	# Get info
	path = posteriorSim[["info"]][["path"]]
	run = posteriorSim[["info"]][["run"]]

	# Get scaling
	dbh_scaling = readRDS(paste0(path, ifelse(!is.null(run), paste0(run, "_"), run), "dbh_normalisation.rds"))

	# Get divergences
	divergences = posteriorSim[["divergences"]]

	# Get posterior fit
	posterior_fit = posteriorSim[["posterior_draws"]]

	# Check-up
	if (!all(class(posterior_fit) == c("CmdStanGQ", "CmdStanFit", "R6")))
		stop("Posterior fit should be a CmdStanGQ object")

	# Get list of extra arguments
	providedArgs = list(...)

	ls_names = names(providedArgs)
	
	highlight_ind = stri_detect(str = ls_names, regex = "highlight")
	data_ind = ls_names == "data"

	# Get data
	if (any(data_ind))
	{
		data = providedArgs[["data"]]

		if (!all(c("dbh", "year", "plot_id", "tree_id") %in% names(data)))
			stop("data must contain at least dbh, year, tree_id, and plot_id")

		if ((length(unique(data[, plot_id])) != 1) || (length(unique(data[, tree_id])) != 1))
		{
			indiv_ind = ls_names == "tree_id"
			plot_ind = ls_names == "plot_id"

			if (!any(indiv_ind) || !any(plot_ind))
				stop("The data provided contains more than one individual/plot, please provide a tree_id and a plot_id or a unique data")

			selectedIndiv = providedArgs[["tree_id"]]
			selectedPlot = providedArgs[["plot_id"]]
			data = data[(tree_id ==  selectedIndiv) & (plot_id == selectedPlot)]
		} else {
			selectedIndiv = data[, unique(tree_id)]
			selectedPlot = data[, unique(plot_id)]
		}
	} else {
		data = readRDS(paste0(path, ifelse(!is.null(run), paste0(run, "_"), run), "treeData.rds"))

		if (!all(c("dbh", "year", "plot_id", "tree_id") %in% names(data)))
			stop("data must contain at least dbh, year, tree_id, and plot_id")

		indiv_ind = ls_names == "tree_id"
		plot_ind = ls_names == "plot_id"

		if (!any(indiv_ind) || !any(plot_ind))
			stop("The data were loaded automatically, but you still need to provide a tree_id and a plot_id")

		selectedIndiv = providedArgs[["tree_id"]]
		selectedPlot = providedArgs[["plot_id"]]
		data = data[(tree_id ==  selectedIndiv) & (plot_id == selectedPlot)]
	}

	# Get indices
	indices = readRDS(paste0(path, ifelse(!is.null(run), paste0(run, "_"), run), "indices.rds"))
	indices = indices[(tree_id == selectedIndiv) & (plot_id == selectedPlot)]

	# Subset draws
	draws = posterior_fit$draws("yearly_latent_dbh")[, , indices[1, index_gen]:indices[.N, index_gen]]
	if (rescale)
		draws = dbh_scaling[variable == "dbh", sd]*draws

	# Info data
	n_iter = dim(draws)[1]
	n_chains = dim(draws)[2]
	n_states = dim(draws)[3]

	# Plot range
	min_yr = data[, min(year)]
	max_yr = data[, max(year)]

	min_val = min(draws)
	min_val = min(min_val, data[, min(dbh)])
	max_val = max(draws)
	max_val = max(max_val, data[, max(dbh)])

	output = list(boundaries = c(min_yr = min_yr, max_yr = max_yr, min_val = min_val, max_val = max_val),
		n_states = n_states)

	# Plot
	if (!is.null(filename))
		pdf(paste0(path, filename), height = 11.25, width = 20)

	par(mar = c(8, 8, 0.5, 0.5), mgp = c(5, 1, 0))
	plot(0, pch = "", xlim = c(min_yr, max_yr), ylim = c(min_val, max_val), axes = TRUE, bg = "transparent",
		xlab = "Year",
		ylab = "Diameter at breast height",
		las = 1, cex.lab = 2.5, cex.axis = 1.75)

	for (iter in 1:n_iter)
	{
		for (chain in 1:n_chains)
			lines(x = min_yr:max_yr, y = draws[iter, chain, ], col = "#3A3A3A55", lwd = 0.15)
	}

	if (!is.null(divergences) && length(divergences) != 0)
	{
		iter_div = divergences %% n_iter
		iter_div[iter_div == 0] = n_iter
		chain_div = (divergences - iter_div) %% n_chains + 1
		for (i in seq_along(divergences))
			lines(x = min_yr:max_yr, y = draws[iter, chain, ], col = "#EF8A47", lwd = 0.75)
		output = append(output, list(divergences = c(iter_div = iter_div, chain_div = chain_div)))
	}

	if (plotMean)
	{
		avg = apply(draws, 3, mean)
		lines(x = min_yr:max_yr, y = avg, col = "#11AED9", lwd = 3)
	}
	
	if (any(highlight_ind))
	{
		h_names = ls_names[highlight_ind]
		for (highlight in h_names)
		{
			if (highlight == "highlight_min_start") # highlight lowest starting trajectory
			{
				if (providedArgs[["highlight_min_start"]])
				{
					iter_id = which.min(draws[, , 1])
					traj = if (iter_id %% n_iter == 0) n_iter else iter_id %% n_iter
					chain_id = (iter_id - traj) %% n_chains + 1
					lines(x = min_yr:max_yr, y = draws[traj, chain_id, ], col = "#CD212A", lwd = 3)
					output = append(output, list(highlight_min_start = c(iter_id = iter_id, traj = traj, chain_id = chain_id)))
				}
			}
			
			if (highlight == "highlight_max_start") # highlight highest starting trajectory
			{
				if (providedArgs[["highlight_max_start"]])
				{
					iter_id = which.max(draws[, , 1])
					traj = if (iter_id %% n_iter == 0) n_iter else iter_id %% n_iter
					chain_id = (iter_id - traj) %% n_chains + 1
					lines(x = min_yr:max_yr, y = draws[traj, chain_id, ], col = "#34568B", lwd = 3)
					output = append(output, list(highlight_max_start = c(iter_id = iter_id, traj = traj, chain_id = chain_id)))
				}
			}
			
			if (highlight == "highlight_min_end") # highlight lowest ending trajectory
			{
				if (providedArgs[["highlight_min_end"]])
				{
					iter_id = which.min(draws[, , n_states])
					traj = if (iter_id %% n_iter == 0) n_iter else iter_id %% n_iter
					chain_id = (iter_id - traj) %% n_chains + 1
					lines(x = min_yr:max_yr, y = draws[traj, chain_id, ], col = "#34568B", lwd = 3)
					output = append(output, list(highlight_min_end = c(iter_id = iter_id, traj = traj, chain_id = chain_id)))
				}
			}
			
			if (highlight == "highlight_max_end") # highlight highest ending trajectory
			{
				if (providedArgs[["highlight_max_end"]])
				{
					iter_id = which.max(draws[, , n_states])
					traj = if (iter_id %% n_iter == 0) n_iter else iter_id %% n_iter
					chain_id = (iter_id - traj) %% n_chains + 1
					lines(x = min_yr:max_yr, y = draws[traj, chain_id, ], col = "#CD212A", lwd = 3)
					output = append(output, list(highlight_max_end = c(iter_id = iter_id, traj = traj, chain_id = chain_id)))
				}
			}
			
			if (highlight %in% c("highlight_max_growth", "highlight_threshold_growth"))
			{
				temporary_dt = data.table(matrix(data = 0, ncol = n_states, nrow = n_iter*n_chains))
				setnames(temporary_dt, paste0("dbh", 1:n_states))
				for (state in 1:n_states)
					temporary_dt[, (paste0("dbh", state)) := as.vector(draws[, , state])]

				for (state in 2:n_states)
				{
					dbh_orig = paste0("dbh", state - 1)
					dbh_end = paste0("dbh", state)
					current_G = paste0("G_", state - 1)
					temporary_dt[, (current_G) := unlist(temporary_dt[, ..dbh_end]) - unlist(temporary_dt[, ..dbh_orig])]
				}

				if (highlight == "highlight_max_growth") # highlight trajectory with max yearly growth
				{
					g_names = paste0("G_", 1:(n_states - 1))
					max_G = max(temporary_dt[, ..g_names])
					iter_id = which(unname(unlist(temporary_dt[, ..g_names]) == max_G))
					row = if (iter_id %% n_iter == 0) n_iter else iter_id %% n_iter
					array_num = which.max(unname(unlist(temporary_dt[row, ..g_names])))
					lines(x = min_yr:max_yr, y = temporary_dt[row, .SD, .SDcols = paste0("dbh", 1:n_states)],
						col = "#93C372", lwd = 3)
					output = append(output, list(highlight_max_growth = c(max_G = max_G, iter_id = row, array_num = array_num)))
				}

				if (highlight == "highlight_threshold_growth") # highlight trajectories with annual growth > threshold
				{
					g_names = paste0("G_", 1:(n_states - 1))
					threshold = providedArgs[["highlight_threshold_growth"]]
					row = which(apply(temporary_dt[, ..g_names] > threshold, 1, any))
					for (i in row)
						lines(x = min_yr:max_yr, y = temporary_dt[i, .SD, .SDcols = paste0("dbh", 1:n_states)],
							col = "#93C37233", lwd = 0.1)
					output = append(output, list(highlight_threshold_growth_rows = row))
				}
			}
		}
	}

	points(data[, year], data[, dbh], pch = 20, cex = 4, col = "#CD212A")
	
	if (!is.null(filename))
	{
		dev.off()
		print(paste0("Figure saved under the name: ", filename))
	}
	return(output)
}

## Function analysing probabilities of extreme errors
probaExtremeObs = function(posteriorSim, ...)
{
	requiredNames = c("posterior_draws", "info", "parents_index", "children_index", "last_child_index", "divergences")
	if (!all(names(posteriorSim) %in% requiredNames))
		stop(paste0("Missing objects in posteriorSim: ", paste0(requiredNames[!(names(posteriorSim) %in% requiredNames)], collapse = ", ")))

	path = posteriorSim[["info"]]$path
	run = posteriorSim[["info"]]$run
	n_obs = posteriorSim[["info"]]$n_obs
	
	proba_extreme_obs_array = posteriorSim[["posterior_draws"]]$draws("proba_extreme_obs")

	proba_mean = 0

	if (dim(proba_extreme_obs_array)[3] != n_obs)
		stop("Dimension of proba_extreme_obs_array mismatch number of observations")

	providedArgs = list(...)
	ls_names = names(providedArgs)
	if (all(c("plot_id", "tree_id") %in% ls_names))
	{
		treeData = readRDS(paste0(path, run, "_treeData.rds"))
		indices = treeData[, which(plot_id == providedArgs[["plot_id"]] & tree_id == providedArgs[["tree_id"]])]
		if (length(indices) == 0)
		{
			warning("Individual not found")
			return(NULL)
		}
		proba_extreme_obs = proba_extreme_obs_array[, , indices]
		proba_mean = apply(proba_extreme_obs, 3, mean)
		names(proba_mean) = paste0("tree_", indices)
	}

	return(proba_mean)
}

## Function to rescale parameters (intercept and slopes)
rescaleParams = function(params, sd_dbh, mu_predictors, sd_predictors)
{
	required_params = c("averageGrowth", "dbh_slope", "dbh_slope2", "pr_slope", "pr_slope2", "tas_slope",
		"tas_slope2", "ph_slope", "ph_slope2", "competition_slope", "sigmaProc")
	
	if (!all(names(params) %in% required_params))
		stop("Some required parameters are missing")

	if (!all(names(mu_predictors) %in% c("pr", "tas", "ph", "basalArea")))
		stop("Some required mu are missing")

	if (!all(names(sd_predictors) %in% c("pr", "tas", "ph", "basalArea")))
		stop("Some required sd are missing")
	
	# beta_0 = scaled beta_0 -  scaled gamma_i * mu_i/sd_i +  scaled delta_j * mu_j^2/sd_j^2
	intercept_rescale = params["averageGrowth"] - params["pr_slope"]*mu_predictors["pr"]/sd_predictors["pr"] -
		params["tas_slope"]*mu_predictors["tas"]/sd_predictors["tas"] - params["ph_slope"]*mu_predictors["ph"]/sd_predictors["ph"] -
		params["competition_slope"]*mu_predictors["basalArea"]/sd_predictors["basalArea"] +
		params["pr_slope2"]*mu_predictors["pr"]^2/sd_predictors["pr"]^2 +
		params["tas_slope2"]*mu_predictors["tas"]^2/sd_predictors["tas"]^2 +
		params["ph_slope2"]*mu_predictors["ph"]^2/sd_predictors["ph"]^2
	
	# beta_1 = scaled beta_1/sd_dbh
	slope_dbh_rescale = params["dbh_slope"]/sd_dbh
	
	# beta_2 = scaled beta_2/sd_dbh^2
	slope_quadratic_dbh_rescale = params["dbh_slope2"]/sd_dbh^2

	# Predictors (gammas and deltas)
	slope_predictors_rescale = numeric(4)
	names(slope_predictors_rescale) = c("pr_slope", "tas_slope", "ph_slope", "competition_slope")

	slope_predictors_rescale["pr_slope"] = params["pr_slope"]/sd_predictors["pr"] -
		2*mu_predictors["pr"]*params["pr_slope2"]/sd_predictors["pr"]^2
	slope_predictors_rescale["tas_slope"] = params["tas_slope"]/sd_predictors["tas"] -
		2*mu_predictors["tas"]*params["tas_slope2"]/sd_predictors["tas"]^2
	slope_predictors_rescale["ph_slope"] = params["ph_slope"]/sd_predictors["ph"] -
		2*mu_predictors["ph"]*params["ph_slope2"]/sd_predictors["ph"]^2
	slope_predictors_rescale["competition_slope"] = params["competition_slope"]/sd_predictors["basalArea"]

	slope_quadratic_predictors_rescale = numeric(3)
	names(slope_quadratic_predictors_rescale) = c("pr_slope2", "tas_slope2", "ph_slope2")

	slope_quadratic_predictors_rescale["pr_slope2"] = params["pr_slope2"]/sd_predictors["pr"]^2
	slope_quadratic_predictors_rescale["tas_slope2"] = params["tas_slope2"]/sd_predictors["tas"]^2
	slope_quadratic_predictors_rescale["ph_slope2"] = params["ph_slope2"]/sd_predictors["ph"]^2

	errors_rescale = numeric(1)
	names(errors_rescale) = c("sigmaProc")

	errors_rescaled["sigmaProc"] = sd_dbh^2*params["sigmaProc"] #! NOT SURE OF THIS!!! I THINK IT DOES NOT WORK NOW THAT I USE LOGNORMAL

	return(list(intercept_rescale = intercept_rescale, slope_dbh_rescale = slope_dbh_rescale,
		slope_quadratic_dbh_rescale = slope_quadratic_dbh_rescale, slope_predictors_rescale = slope_predictors_rescale,
		slope_quadratic_predictors_rescale = slope_quadratic_predictors_rescale, errors_rescale = errors_rescale))
}

## Function to compute growth, the data table must be sorted by year within tree id and plot id
computeGrowth = function(dt, col = "growth", byCols = c("plot_id", "tree_id"), radialGrowth = TRUE)
{
	if (!all(c("dbh", "year", byCols) %in% names(dt)))
		stop(paste("The data table must contains at least contains the columns dbh, year,", paste(byCols, collapse = ", ")))
	while (col %in% names(dt))
	{
		newcol = paste0(col, rnorm(1))
		warning(paste0("The name `", col, "` is already used in the data table. The result was stored in col `", newcol, "` instead"))
		col = newcol
	}
	dt[, (col) := (shift(dbh, n = 1, type = "lead", fill = NA) - dbh)/(shift(year, n = 1, type = "lead", fill = NA) - year), by = byCols]

	if (radialGrowth)
		dt[, (col) := dt[, ..col]/2]

	if (!("deltaYear" %in% names(dt)))
		dt[, deltaYear := shift(year, n = 1, type = "lead", fill = NA) - year, by = byCols]
}

## Function computing the expected growth in the case growth ~ lognormal. Not sure that the first moment best represents growth due to variance!
growth_fct = function(dbh, pr, tas, ph, basalArea, params, sd_dbh, standardised_dbh = TRUE, standardised_params = TRUE,
	standardised_variables = FALSE, ...)
{
	sigmaProc = params[["sigmaProc"]]
	G_average = exp(growth_fct_meanlog(dbh, pr, tas, ph, basalArea, params, sd_dbh, standardised_dbh,
		standardised_params, standardised_variables, ...) + sigmaProc^2/2) # Formula from the average of a lognormal
	
	return(G_average)
}

## Function computing the expected growth on the log scale (i.e., corresponds to the parameter meanlog of lognormal distribution)
growth_fct_meanlog = function(dbh, pr, tas, ph, basalArea, params, sd_dbh, standardised_dbh = TRUE, standardised_params = TRUE,
	standardised_variables = FALSE, ...)
{
	G = NaN
	if (!standardised_dbh)
		dbh = dbh/sd_dbh

	if (!standardised_params && !standardised_variables) # i.e., params from rescaleParams function; explanatory variables from data
	{
		if (class(params) != "list")
			stop("Parameters have been rescaled, list created by rescaleParams expected")

		intercept = params[["intercept_rescale"]]

		dbh_slope = params[["slope_dbh_rescale"]]
		dbh_slope2 = params[["slope_quadratic_dbh_rescale"]]
		
		pr_slope = params[["slope_predictors_rescale"]]["pr_slope"]
		tas_slope = params[["slope_predictors_rescale"]]["tas_slope"]
		ph_slope = params[["slope_predictors_rescale"]]["ph_slope"]
		competition_slope = params[["slope_predictors_rescale"]]["competition_slope"]

		pr_slope2 = params[["slope_quadratic_predictors_rescale"]]["pr_slope2"]
		tas_slope2 = params[["slope_quadratic_predictors_rescale"]]["tas_slope2"]
		ph_slope2 = params[["slope_quadratic_predictors_rescale"]]["ph_slope2"]
		
		G = sd_dbh * exp(intercept + dbh_slope*dbh + dbh_slope2*dbh^2 + pr_slope*pr + pr_slope2*pr^2 + tas_slope*tas + tas_slope2*tas^2 +
			ph_slope*ph + ph_slope2*ph^2 + competition_slope*basalArea)
	}

	if (standardised_params && !standardised_variables) # i.e., params from stan output; explanatory variables from data
	{
		providedArgs = list(...)
		ls_names = names(providedArgs)
		scaling_ind = stri_detect(str = ls_names, regex = "scaling")
		if (sum(scaling_ind) == 1)
		{
			required_params = "scaling"
			single = TRUE
		} else {
			required_params = c("dbh_scaling", "clim_scaling", "ph_scaling", "ba_scaling")
			single = FALSE
		}

		if (!all(required_params %in% ls_names))
			stop("Scaling parameters not provided completly")

		if (single)
		{
			scaling_dt = providedArgs[["scaling"]]
			setkey(scaling_dt, variable)
		} else {
			clim_scaling = providedArgs[["clim_scaling"]]
			ph_scaling = providedArgs[["ph_scaling"]]
			ba_scaling = providedArgs[["ba_scaling"]]

			scaling_dt = rbindlist(list(clim_scaling, ph_scaling, ba_scaling))
			setkey(scaling_dt, variable)
		}
		
		pr = (pr - scaling_dt["pr", mu])/scaling_dt["pr", sd]
		tas = (tas - scaling_dt["tas", mu])/scaling_dt["tas", sd]
		ph = (ph - scaling_dt["ph", mu])/scaling_dt["ph", sd]
		basalArea = (basalArea - scaling_dt["standBasalArea_interp", mu])/scaling_dt["standBasalArea_interp", sd]

		standardised_variables = TRUE
	}

	if (standardised_params && standardised_variables) # i.e., params from stan output; explanatory variables from above or already std.
	{
		intercept = params["averageGrowth"]

		dbh_slope = params["dbh_slope"]
		dbh_slope2 = params["dbh_slope2"]
		
		pr_slope = params["pr_slope"]
		tas_slope = params["tas_slope"]
		ph_slope = params["ph_slope"]
		competition_slope = params["competition_slope"]

		pr_slope2 = params["pr_slope2"]
		tas_slope2 = params["tas_slope2"]
		ph_slope2 = params["ph_slope2"]
		
		G = sd_dbh * exp(intercept + dbh_slope*dbh + dbh_slope2*dbh^2 + pr_slope*pr + pr_slope2*pr^2 + tas_slope*tas + tas_slope2*tas^2 +
			ph_slope*ph + ph_slope2*ph^2 + competition_slope*basalArea)
	}

	if (!standardised_params && standardised_variables)
		warning("This combination of scaled and non scaled is not coded")
	return(G)	
}

## Function to compute the optimum value of response variables with a quadratic term
optimumPredictorValue = function(slope, slope2, scaling_mu = NULL, scaling_sd = NULL)
{
	if (is.null(scaling_mu))
		scaling_mu = 0

	if (is.null(scaling_sd))
		scaling_mu = 1
	
	return(optimum = scaling_mu - scaling_sd*slope/(2*slope2))
}

## Function to plot growth vs a response variable with the uncertainty related to parameters estimation (minus process error)
plotGrowth = function(species, run, variables, selected_plot_id = NULL, init_dbh = NULL, extension = "pdf", ...)
{
	# Local function to format data
	formatNewData = function(tree_path, run, variable, avg_values, n_env, n_dbh_new, lower_dbh, upper_dbh, minGradient, maxGradient)
	{
		stanData_ssm = readRDS(paste0(tree_path, run, "_stanData.rds"))
		stanData_classic = readRDS(paste0(tree_path, run, "_stanData_classic.rds"))

		n_climate_new = n_env[variable]

		pr_rep = (rep(avg_values["pr_mean"], n_climate_new) - stanData_classic$pr_mu)/stanData_classic$pr_sd
		tas_rep = (rep(avg_values["tas_mean"], n_climate_new) - stanData_classic$tas_mu)/stanData_classic$tas_sd
		ph_rep = (rep(avg_values["ph_mean"], n_climate_new) - stanData_classic$ph_mu)/stanData_classic$ph_sd
		ba_rep = (rep(25, n_climate_new) - stanData_classic$ba_mu)/stanData_classic$ba_sd

		scaled_gradient = seq(minGradient[variable], maxGradient[variable], length.out = n_climate_new)

		if (variable == "pr")
		{
			gradient_ssm = (scaled_gradient - stanData_ssm$pr_mu)/stanData_ssm$pr_sd
			gradient_classic = (scaled_gradient - stanData_classic$pr_mu)/stanData_classic$pr_sd
			stanData_ssm$x_r = c(gradient_ssm, tas_rep, ph_rep, ba_rep)
			stanData_classic$x_r = c(gradient_classic, tas_rep, ph_rep, ba_rep)
		}

		if (variable == "tas")
		{
			gradient_ssm = (scaled_gradient - stanData_ssm$tas_mu)/stanData_ssm$tas_sd
			gradient_classic = (scaled_gradient - stanData_classic$tas_mu)/stanData_classic$tas_sd
			stanData_ssm$x_r = c(pr_rep, gradient_ssm, ph_rep, ba_rep)
			stanData_classic$x_r = c(pr_rep, gradient_classic, ph_rep, ba_rep)
		}

		if (variable == "ph")
		{
			gradient_ssm = (scaled_gradient - stanData_ssm$ph_mu)/stanData_ssm$ph_sd
			gradient_classic = (scaled_gradient - stanData_classic$ph_mu)/stanData_classic$ph_sd
			stanData_ssm$x_r = c(pr_rep, tas_rep, gradient_ssm, ba_rep)
			stanData_classic$x_r = c(pr_rep, tas_rep, gradient_classic, ba_rep)
		}

		stanData_ssm$n_climate_new = n_climate_new
		stanData_ssm$n_dbh_new = n_dbh_new
		stanData_ssm$n_growth = stanData_ssm$n_children # n_children is also n_growth (i.e. the number of growth intervals)!
		stanData_ssm$lower_bound = unname(lower_dbh)
		stanData_ssm$upper_bound = unname(upper_dbh)

		stanData_classic$n_climate_new = n_climate_new
		stanData_classic$n_dbh_new = n_dbh_new
		stanData_classic$lower_bound = unname(lower_dbh)
		stanData_classic$upper_bound = unname(upper_dbh)

		return(list(stanData_ssm = stanData_ssm, stanData_classic = stanData_classic, gradient_ssm = gradient_ssm,
			gradient_classic = gradient_classic, scaled_gradient = scaled_gradient))
	}

	# Paths and check-up
	tree_path = paste0("./", species, "/")
	if (!dir.exists(tree_path))
		stop(paste0("Path not found for species <", species, ">."))

	if (!all(variables %in% c("pr", "tas", "ph")))
		stop("Variables are limited to 'pr', 'tas', and 'ph'")

	# Results
	# --- State-Space Model approach
	info_lastRun = getLastRun(path = tree_path, begin = "growth-", extension = "_main.rds$", run = run)
	lastRun = info_lastRun[["file"]]
	ssm = readRDS(paste0(tree_path, lastRun))
	nb_nfi = ssm$metadata()$stan_variable_sizes$etaObs

	# --- Classic approach
	info_lastRun = getLastRun(path = tree_path, begin = "growth-", extension = "_classic.rds$", run = run)
	lastRun = info_lastRun[["file"]]
	classic = readRDS(paste0(tree_path, lastRun))

	# Associated estimated parameters
	params_names = c("averageGrowth", "dbh_slope", "dbh_slope2", "pr_slope", "pr_slope2", "tas_slope", "tas_slope2",
		"ph_slope", "ph_slope2", "competition_slope", "etaObs", "proba", "sigmaProc")

	if (nb_nfi > 1)
		params_names = expand(params_names, nb_nfi)[["new_names"]]

	# --- Mean estimation
	estimated_params_ssm = getParams(model_cmdstan = ssm, params_names = params_names)
	estimated_params_classic = getParams(model_cmdstan = classic, params_names = params_names)

	# Simulate growth along an environmental gradient
	# --- Stan models to simulate growth
	gq_model_ssm = cmdstan_model("generate_growth.stan")
	gq_model_classic = cmdstan_model("generate_growth_classic.stan")

	# --- Environmental space
	# ------ Get list of arguments
	providedArgs = list(...)
	nbArgs = length(providedArgs)

	ls_names = names(providedArgs)

	tas_ind = stri_detect(str = ls_names, regex = "tas_")
	pr_ind = stri_detect(str = ls_names, regex = "pr_")
	ph_ind = stri_detect(str = ls_names, regex = "ph_")
	ba_ind = stri_detect(str = ls_names, regex = "ba_")

	# ------ Temperature
	if (any(tas_ind))
	{
		if (!all(c("tas_min", "tas_max", "tas_mean") %in% ls_names[tas_ind]))
			stop("If you want to provide informations on temperature, please provide tas_min, tas_max, and tas_mean")
		tas_min = providedArgs[["tas_min"]]
		tas_max = providedArgs[["tas_max"]]
		tas_mean = providedArgs[["tas_mean"]]
	} else {
		tas_min = -5
		tas_max = 35
		tas_mean = 12.5
	}
	n_tas = 200

	# ------ Precipitation
	if (any(pr_ind))
	{
		if (!all(c("pr_min", "pr_max", "pr_mean") %in% ls_names[pr_ind]))
			stop("If you want to provide informations on temperature, please provide pr_min, pr_max, and pr_mean")
		pr_min = providedArgs[["pr_min"]]
		pr_max = providedArgs[["pr_max"]]
		pr_mean = providedArgs[["pr_mean"]]
	} else {
		pr_min = 350
		pr_max = 1350
		pr_mean = 650
	}
	n_pr = 500

	# ------ Ph
	if (any(ph_ind))
	{
		if (!all(c("ph_min", "ph_max", "ph_mean") %in% ls_names[ph_ind]))
			stop("If you want to provide informations on temperature, please provide ph_min, ph_max, and ph_mean")
		ph_min = providedArgs[["ph_min"]]
		ph_max = providedArgs[["ph_max"]]
		ph_mean = providedArgs[["ph_mean"]]
	} else {
		ph_min = 4.8
		ph_max = 6.2
		ph_mean = 5.5
	}
	n_ph = 10

	# Diameter space
	dbh_ind = stri_detect(str = ls_names, regex = ".*_dbh$")
	if (any(dbh_ind))
	{
		if (!all(ls_names[ph_ind] %in% c("dbh_min", "dbh_max")))
			stop("If you want to provide informations on diameters, please provide dbh_min and dbh_max")
		lower_dbh = providedArgs[["lower_dbh"]]
		upper_dbh = providedArgs[["upper_dbh"]]
	} else {
		treeData = readRDS(paste0(tree_path, run, "_treeData.rds"))
		lower_dbh = quantile(treeData$dbh, seq(0, 1, 0.025))["2.5%"]
		upper_dbh = quantile(treeData$dbh, seq(0, 1, 0.025))["97.5%"]
	}
	n_dbh_new = round(unname(round(upper_dbh - lower_dbh) + 1)/5)

	# Simulate growth along the environmental gradient for many dbh
	# --- Common variables
	n_chains = ssm$num_chains() # Same for classic approach
	avg_values = c(pr_mean = pr_mean, tas_mean = tas_mean, ph_mean = ph_mean)
	minGradient = c(pr = pr_min, tas = tas_min, ph = ph_min)
	maxGradient = c(pr = pr_max, tas = tas_max, ph = ph_max)
	n_env = c(pr = n_pr, tas = n_tas, ph = n_ph)
	
	for (currentVar in variables)
	{
		stanData = formatNewData(tree_path, run, currentVar, avg_values, n_env, n_dbh_new, lower_dbh, upper_dbh,
			minGradient, maxGradient)

		# --- Generate quantities
		generate_quantities_ssm = gq_model_ssm$generate_quantities(ssm$draws(), data = stanData[["stanData_ssm"]], parallel_chains = n_chains)
		generate_quantities_classic = gq_model_classic$generate_quantities(classic$draws(), data = stanData[["stanData_classic"]],
			parallel_chains = n_chains)

		simulatedGrowth_ssm = generate_quantities_ssm$draws("simulatedGrowth_avg")
		simulatedGrowth_classic = generate_quantities_classic$draws("simulatedGrowth_avg")

		# Plot simulations
		# --- Select the optimum dbh for growth
		optimumDbh_ssm = optimumPredictorValue(slope = estimated_params_ssm["dbh_slope"], slope2 = estimated_params_ssm["dbh_slope2"],
			scaling_sd = stanData[["stanData_ssm"]]$sd_dbh)
		optimumDbh_classic = optimumPredictorValue(slope = estimated_params_classic["dbh_slope"], slope2 = estimated_params_classic["dbh_slope2"],
			scaling_sd = stanData[["stanData_classic"]]$sd_dbh)

		new_dbh = seq(lower_dbh, upper_dbh, length.out = n_dbh_new)
		optimum_ind_dbh_ssm = which.min(abs(new_dbh - optimumDbh_ssm))
		optimum_ind_dbh_classic = which.min(abs(new_dbh - optimumDbh_classic))

		# --- Select data according to optimum dbh
		selectedData_ssm = paste0("simulatedGrowth_avg[", 1:stanData[["stanData_ssm"]]$n_climate_new, ",", optimum_ind_dbh_ssm, "]")
		selectedData_classic = paste0("simulatedGrowth_avg[", 1:stanData[["stanData_classic"]]$n_climate_new, ",", optimum_ind_dbh_classic, "]")
		
		growth_ssm = simulatedGrowth_ssm[, , selectedData_ssm]
		growth_ssm = stanData[["stanData_ssm"]]$sd_dbh*growth_ssm

		growth_classic = simulatedGrowth_classic[, , selectedData_classic]
		growth_classic = stanData[["stanData_classic"]]$sd_dbh*growth_classic

		# --- Compute the 2.5 and 97.5 quantiles due to uncertainty on parameters (no process error!)
		growth_q2.5_ssm = apply(X = growth_ssm, FUN = quantile, MARGIN = 3, probs = 0.025)
		growth_q97.5_ssm = apply(X = growth_ssm, FUN = quantile, MARGIN = 3, probs = 0.975)
		growth_ssm = apply(X = growth_ssm, FUN = mean, MARGIN = 3)

		growth_q2.5_classic = apply(X = growth_classic, FUN = quantile, MARGIN = 3, probs = 0.025)
		growth_q97.5_classic = apply(X = growth_classic, FUN = quantile, MARGIN = 3, probs = 0.975)
		growth_classic = apply(X = growth_classic, FUN = mean, MARGIN = 3)

		# --- plot
		if (variables == "pr")
			selectedVariable = "Precipitation"
		if (variables == "tas")
			selectedVariable = "Temperature"
		if (variables == "ph")
			selectedVariable = "pH"
		
		filename = paste0(tree_path, "ssm-vs-classic_approach_", selectedVariable, ".", extension)

		if (extension == "pdf")
			pdf(filename, height = 10, width = 10)
		if (extension == "tex")
			tikz(filename, height = 3, width = 3)
		plot(stanData[["scaled_gradient"]], growth_ssm, xlab = selectedVariable, ylab = "Growth", col = "#F4C430", type = "l", lwd = 2, lty = 1,
			ylim = c(min(c(growth_q2.5_ssm, growth_q2.5_classic)), max(c(growth_q97.5_ssm, growth_q97.5_classic))))
		lines(stanData[["scaled_gradient"]], growth_classic, col = "#034C4F", lwd = 2, lty = 2)
		polygon(c(rev(stanData[["scaled_gradient"]]), stanData[["scaled_gradient"]]), c(rev(growth_q2.5_ssm), growth_q97.5_ssm),
			col = "#F4C43022", border = NA)
		polygon(c(rev(stanData[["scaled_gradient"]]), stanData[["scaled_gradient"]]), c(rev(growth_q2.5_classic), growth_q97.5_classic),
			col = "#034C4F22", border = NA)
		legend(x = "topright", legend = c("SSM", "Classic"), fill = c("#F4C430", "#034C4F"), box.lwd = 0)
		dev.off()
	}

	# plot growth posterior for a given time series of environmental variables and an initial dbh (if provided)
	if (!is.null(selected_plot_id) && !is.null(init_dbh))
	{
		# --- Prepare climate
		dataEnv_ls = getEnvSeries(species, run)
		n_growingYears = dataEnv_ls[["dataEnv"]][selected_plot_id, .N] - 1
		precipitations = dataEnv_ls[["dataEnv"]][selected_plot_id, pr]
		temperatures = dataEnv_ls[["dataEnv"]][selected_plot_id, tas]
		ph = dataEnv_ls[["dataEnv"]][selected_plot_id, ph]
		basalAreas = dataEnv_ls[["dataEnv"]][selected_plot_id, standBasalArea_interp]

		# --- Prepare new stan data
		# ------ Load stan data
		stanData_ssm = readRDS(paste0(tree_path, run, "_stanData.rds"))
		stanData_classic = readRDS(paste0(tree_path, run, "_stanData_classic.rds"))

		# ------ Add the new environment (x_r)
		stanData_ssm$x_r = c((precipitations - dataEnv_ls[["scaling_clim_ssm"]]["pr", mu])/dataEnv_ls[["scaling_clim_ssm"]]["pr", sd],
			(temperatures - dataEnv_ls[["scaling_clim_ssm"]]["tas", mu])/dataEnv_ls[["scaling_clim_ssm"]]["tas", sd],
			(ph - dataEnv_ls[["scaling_ph_ssm"]]["ph", mu])/dataEnv_ls[["scaling_ph_ssm"]]["ph", sd],
			(basalAreas - dataEnv_ls[["scaling_ba_ssm"]]["standBasalArea_interp", mu])/
				dataEnv_ls[["scaling_ba_ssm"]]["standBasalArea_interp", sd])

		precipitations = (precipitations - dataEnv_ls[["scaling_clim_classic"]]["pr_avg", mu])/dataEnv_ls[["scaling_clim_classic"]]["pr_avg", sd]
		temperatures = (temperatures - dataEnv_ls[["scaling_clim_classic"]]["tas_avg", mu])/dataEnv_ls[["scaling_clim_classic"]]["tas_avg", sd]
		ph = (ph - dataEnv_ls[["scaling_ph_classic"]]["ph", mu])/dataEnv_ls[["scaling_ph_classic"]]["ph", sd]
		basalAreas = (basalAreas - dataEnv_ls[["scaling_ba_classic"]]["standBasalArea_interp_avg", mu])/
			dataEnv_ls[["scaling_ba_classic"]]["standBasalArea_interp_avg", sd]

		stanData_classic$x_r = c(precipitations, temperatures, ph, basalAreas)
		stanData_classic$x_r_avg = c(mean(precipitations), mean(temperatures), mean(ph), mean(basalAreas))

		# ------ Add the new dimensions
		stanData_ssm$n_climate_new = length(temperatures)
		stanData_ssm$n_years = n_growingYears
		stanData_ssm$n_growth = stanData_ssm$n_children # n_children is also n_growth (i.e. the number of growth intervals)!
		stanData_ssm$dbh0 = init_dbh

		stanData_classic$n_climate_new = length(temperatures)
		stanData_classic$n_years = n_growingYears
		stanData_classic$dbh0 = init_dbh

		# --- Generate quantities
		# ------ Stan models to simulate growth
		gq_model_ssm = cmdstan_model("generate_posterior.stan")
		gq_model_classic = cmdstan_model("generate_posterior_classic.stan")

		# ------ Run simulations
		generate_quantities_ssm = gq_model_ssm$generate_quantities(ssm$draws(), data = stanData_ssm, parallel_chains = n_chains)
		generate_quantities_classic = gq_model_classic$generate_quantities(classic$draws(), data = stanData_classic, parallel_chains = n_chains)

		simulatedGrowth_ssm = stanData_ssm$sd_dbh*generate_quantities_ssm$draws(paste0("current_dbh[", stanData_ssm$n_climate_new, "]"))
		simulatedGrowth_classic = stanData_classic$sd_dbh*generate_quantities_classic$draws(paste0("current_dbh[",
			stanData_classic$n_climate_new, "]"))
		simulatedGrowth_classic_avg = stanData_classic$sd_dbh*generate_quantities_classic$draws("final_dbh")

		simulatedGrowth_avg_ssm = generate_quantities_ssm$draws("simulatedGrowth_avg")
		simulatedGrowth_avg_classic = generate_quantities_classic$draws("simulatedGrowth_avg")
		simulatedGrowth_avg_clim_avg = generate_quantities_classic$draws("simulatedGrowth_avg_clim_avg")

		# --- Compute the 2.5 and 97.5 quantiles due to uncertainty on parameters (no process error!)
		simulatedGrowth_avg_ssm_q2.5 = stanData_ssm$sd_dbh * apply(X = simulatedGrowth_avg_ssm, FUN = quantile, MARGIN = 3, probs = 0.025)
		simulatedGrowth_avg_ssm_q97.5 = stanData_ssm$sd_dbh * apply(X = simulatedGrowth_avg_ssm, FUN = quantile, MARGIN = 3, probs = 0.975)
		simulatedGrowth_avg_ssm = stanData_ssm$sd_dbh * apply(X = simulatedGrowth_avg_ssm, FUN = mean, MARGIN = 3)

		simulatedGrowth_avg_classic_q2.5 = stanData_ssm$sd_dbh *
			apply(X = simulatedGrowth_avg_classic, FUN = quantile, MARGIN = 3, probs = 0.025)
		simulatedGrowth_avg_classic_q97.5 = stanData_ssm$sd_dbh *
			apply(X = simulatedGrowth_avg_classic, FUN = quantile, MARGIN = 3, probs = 0.975)
		simulatedGrowth_avg_classic = stanData_ssm$sd_dbh * apply(X = simulatedGrowth_avg_classic, FUN = mean, MARGIN = 3)

		simulatedGrowth_avg_clim_avg_q2.5 = stanData_ssm$sd_dbh/n_growingYears *
			apply(X = simulatedGrowth_avg_clim_avg, FUN = quantile, MARGIN = 3, probs = 0.025)
		simulatedGrowth_avg_clim_avg_q97.5 = stanData_ssm$sd_dbh/n_growingYears *
			apply(X = simulatedGrowth_avg_clim_avg, FUN = quantile, MARGIN = 3, probs = 0.975)
		simulatedGrowth_avg_clim_avg = stanData_ssm$sd_dbh/n_growingYears * apply(X = simulatedGrowth_avg_clim_avg, FUN = mean, MARGIN = 3)

		year_start = dataEnv_ls[["dataEnv"]][selected_plot_id, min(year)]
		year_end = dataEnv_ls[["dataEnv"]][selected_plot_id, max(year)] - 1

		filename = paste0(tree_path, "ssm_approach_time_series.", extension)
		if (extension == "pdf")
			pdf(filename, height = 10, width = 10)
		if (extension == "tex")
		{
			tikz(filename, height = 1.2, width = 3.883282)
			op = par(mar = c(2.5, 2.5, 0.8, 0.8), mgp = c(1.5, 0.3, 0), tck = -0.015)
		}
		plot(year_start:year_end, simulatedGrowth_avg_ssm, type = "l", xlab = "Year", ylab = "Growth", lwd = 2, col = "#F4C430",
			ylim = c(min(simulatedGrowth_avg_ssm_q2.5), max(simulatedGrowth_avg_ssm_q97.5)))
		polygon(c(rev(year_start:year_end), year_start:year_end), c(rev(simulatedGrowth_avg_ssm_q2.5), simulatedGrowth_avg_ssm_q97.5),
			col = "#F4C43022", border = NA)
		legend(x = "topleft", legend = "SSM", fill = "#F4C430", box.lwd = 0)
		dev.off()

		filename = paste0(tree_path, "classic_approach_time_series.", extension)
		if (extension == "pdf")
			pdf(filename, height = 10, width = 10)
		if (extension == "tex")
		{
			tikz(filename, height = 1.2, width = 3.883282)
			op = par(mar = c(2.5, 2.5, 0.8, 0.8), mgp = c(1.5, 0.3, 0), tck = -0.015)
		}
		plot(year_start:year_end, simulatedGrowth_avg_classic, type = "l", xlab = "Year", ylab = "Growth", lwd = 2, col = "#034C4F",
			ylim = c(min(simulatedGrowth_avg_classic_q2.5), max(simulatedGrowth_avg_classic_q97.5)))
		polygon(c(rev(year_start:year_end), year_start:year_end), c(rev(simulatedGrowth_avg_classic_q2.5), simulatedGrowth_avg_classic_q97.5),
			col = "#034C4F22", border = NA)
		abline(h = simulatedGrowth_avg_clim_avg, lwd = 2, lty = 2)
		legend(x = "topleft", legend = "Classic", fill = "#034C4F", box.lwd = 0)
		dev.off()
	}

	return(list(optimumDbh_ssm = optimumDbh_ssm, optimumDbh_classic = optimumDbh_classic, filename = filename))
}

## Function to get the environment for a given species and run (i.e., a given index set)
getEnvSeries = function(species, run, clim_folder = "/home/amael/project_ssm/inventories/growth/",
	standBasalArea_folder = "/home/amael/project_ssm/inventories/growth/", soil_folder = "/home/amael/project_ssm/inventories/growth/")
{
	# Load data and check-up
	# --- Indices
	indices_path = paste0("./", species, "/")
	if (!dir.exists(indices_path))
		stop(paste0("Path not found for species <", species, ">."))
	indices = readRDS(paste0(indices_path, run, "_indices.rds"))[["indices_avg"]]
	indices[, year := NULL]
	
	# --- Climate
	if (!dir.exists(clim_folder))
		stop(paste0("Folder\n\t", clim_folder, "\ndoes not exist"))
	env = readRDS(paste0(clim_folder, "europe_reshaped_climate.rds"))

	# --- Basal area (interpolated data)
	if (!dir.exists(standBasalArea_folder))
		stop(paste0("Folder\n\t", standBasalArea_folder, "\ndoes not exist"))
	standBasalArea = readRDS(paste0(standBasalArea_folder, "europe_reshaped_standBasalArea.rds"))

	# --- Soil data
	if (!dir.exists(soil_folder))
		stop(paste0("Folder\n\t", soil_folder, "\ndoes not exist"))
	soil = readRDS(paste0(soil_folder, "europe_reshaped_soil.rds"))
	setkey(soil, plot_id)

	# --- Scalings
	# ------ Approach: ssm
	scaling_dbh = readRDS(paste0(indices_path, run, "_dbh_normalisation.rds"))
	setkey(scaling_dbh, variables)
	scaling_ba_ssm = readRDS(paste0(indices_path, run, "_ba_normalisation.rds"))
	setkey(scaling_ba_ssm, variables)
	scaling_clim_ssm = readRDS(paste0(indices_path, run, "_climate_normalisation.rds"))
	setkey(scaling_clim_ssm, variables)
	scaling_ph_ssm = readRDS(paste0(indices_path, run, "_ph_normalisation.rds"))
	setkey(scaling_ph_ssm, variables)

	# ------ Approach: classic (dbh is the same so not loaded twice)
	scaling_ba_classic = readRDS(paste0(indices_path, run, "_ba_normalisation_classic.rds"))
	setkey(scaling_ba_classic, variables)
	scaling_clim_classic = readRDS(paste0(indices_path, run, "_climate_normalisation_classic.rds"))
	setkey(scaling_clim_classic, variables)
	scaling_ph_classic = readRDS(paste0(indices_path, run, "_ph_normalisation_classic.rds"))
	setkey(scaling_ph_classic, variables)

	# Merge climate with stand basal area and soil data
	env = env[standBasalArea, on = c("plot_id", "year")]
	env = env[soil, on = "plot_id"]

	# Create time series environment
	nClim = indices[, sum(year_end - year_start + 1)]

	dataEnv = setnames(data.table(matrix(data = 0, nrow = nClim, ncol = ncol(env))), names(env))
	dataEnv[, plot_id := as.character(plot_id)]
	cols = names(env)
	start = 1

	for (i in seq_len(indices[, .N]))
	{
		end = start + indices[i , year_end - year_start]
		dataEnv[start:end, c(cols) := env[indices[i, index_clim_start]:indices[i, index_clim_end]]]
		start = end + 1

		if (i %% 100 == 0)
			print(paste0(round(i*100/indices[, .N], 2), "% done"))
	}
	print("100% done")

	setkey(dataEnv, plot_id, year)
	return(list(dataEnv = dataEnv, scaling_dbh = scaling_dbh,
		scaling_ba_ssm = scaling_ba_ssm, scaling_clim_ssm = scaling_clim_ssm, scaling_ph_ssm = scaling_ph_ssm,
		scaling_ba_classic = scaling_ba_classic, scaling_clim_classic = scaling_clim_classic, scaling_ph_classic = scaling_ph_classic))
}

## Function to compare tree ring time-series with simulated time series from the fitted models
validationTreeRing = function(species, run)
{
	# Local function
	correl_SSM_classic_data = function(predicted_growth_ssm, predicted_growth_classic, tree_data, method = "pearson")
	{
		correl_ssm = cor(predicted_growth_ssm, tree_data[, dbh_increment_in_mm], method = method)
		correl_pr_ssm = cor(predicted_growth_ssm, tree_data[, pr], method = method)
		correl_tas_ssm = cor(predicted_growth_ssm, tree_data[, tas], method = method)

		## CLassic
		correl_classic = cor(predicted_growth_classic, tree_data[, dbh_increment_in_mm], method = method)
		correl_pr_classic = cor(predicted_growth_classic, tree_data[, pr], method = method)
		correl_tas_classic = cor(predicted_growth_classic, tree_data[, tas], method = method)

		## Data
		correl_pr_data = cor(tree_data[, dbh_increment_in_mm], tree_data[, pr], method = method)
		correl_tas_data = cor(tree_data[, dbh_increment_in_mm], tree_data[, tas], method = method)

		dt_correl = data.table(var1 = c("growth_ssm", "growth_ssm", "growth_ssm",
				"growth_classic", "growth_classic", "growth_classic",
				"growth_data", "growth_data"),
			var2 = c("growth_data", "pr", "tas",
				"growth_data", "pr", "tas",
				"pr", "tas"),
			corr = c(correl_ssm, correl_pr_ssm, correl_tas_ssm,
				correl_classic, correl_pr_classic, correl_tas_classic,
				correl_pr_data, correl_tas_data)
			)
		return(dt_correl)
	}

	# Load and prepare data
	# --- Tree data
	tree_data = readRDS("/home/amael/project_ssm/inventories/treeRings/treeRings-climate.rds")

	tree_data = tree_data[(speciesName_sci == species) & (country %in% c("France", "Germany", "Sweden"))]
	if (tree_data[, .N] == 0)
		stop("Empty dataset")

	setkey(tree_data, tree_id, year)

	# --- Indexing
	parents_index = tree_data[, .I[which.min(year)], by = .(tree_id)][, V1] # tree_id is enough here
	last_child_index = tree_data[, .I[which.max(year)], by = .(tree_id)][, V1]

	nbGrowingYears = tree_data[last_child_index, year] - tree_data[parents_index, year]
	n_indiv = length(tree_data[, unique(tree_id)])
	if (n_indiv != length(parents_index))
		stop("Dimensions mismatch between n_indiv and parents_index")

	start_ind = integer(length = n_indiv)
	end_ind = integer(length = n_indiv)

	start_ind[1] = 1

	for (i in seq_len(n_indiv - 1))
	{
		end_ind[i] = start_ind[i] + nbGrowingYears[i]
		start_ind[i + 1] = end_ind[i] + 1
	}

	end_ind[n_indiv] = start_ind[n_indiv] + nbGrowingYears[n_indiv]
	if (end_ind[n_indiv] != tree_data[, .N])
		stop("dimensions mismatch between end_ind and tree_data")

	# --- Load fitted models
	# ------ Common variables
	tree_path = paste0("./", species, "/")
	if (!dir.exists(tree_path))
		stop(paste0("Path not found for species <", species, ">."))

	# ------ Load stand-alone generate_quantities() stan models
	gq_model_ssm = cmdstan_model("generate_posterior_treeRing_ssm.stan")
	gq_model_classic = cmdstan_model("generate_posterior_treeRing_classic.stan")

	# ------ Load results
	info_lastRun = getLastRun(path = tree_path, begin = "^growth-", extension = "_main.rds$", format = "ymd", run = run, hour = TRUE)
	ssm = readRDS(paste0(tree_path, info_lastRun[["file"]]))

	info_lastRun = getLastRun(path = tree_path, begin = "^growth-", extension = "_classic.rds$", format = "ymd", run = run, hour = TRUE)
	classic = readRDS(paste0(tree_path, info_lastRun[["file"]]))

	n_chains = ssm$num_chains()

	# --- Prepare stan data
	# ------ Load
	stanData_ssm = readRDS(paste0(tree_path, run, "_stanData.rds"))
	stanData_classic = readRDS(paste0(tree_path, run, "_stanData_classic.rds"))

	# ------ Add dimensions
	# --------- SSM
	stanData_ssm$time_series_length = tree_data[, .N]
	stanData_ssm$n_growth = stanData_ssm$n_children
	stanData_ssm$n_indiv_new = n_indiv

	# --------- Classic
	stanData_classic$time_series_length = tree_data[, .N]
	stanData_classic$n_indiv_new = n_indiv

	# ------ Add diameters
	stanData_ssm$dbh0 = tree_data[parents_index, starting_dbh]
	stanData_classic$dbh0 = tree_data[parents_index, starting_dbh]

	# ------ Add environment
	# --------- SSM
	stanData_ssm$pr_new = (tree_data[, pr] - stanData_ssm$pr_mu)/stanData_ssm$pr_sd
	stanData_ssm$tas_new = (tree_data[, tas] - stanData_ssm$tas_mu)/stanData_ssm$tas_sd
	stanData_ssm$ph_new = (tree_data[, ph] - stanData_ssm$ph_mu)/stanData_ssm$ph_sd
	stanData_ssm$basal_new = rep(0, tree_data[, .N]) # Corresponds to average basal area on the std scale

	# --------- Classic
	stanData_classic$pr_new = (tree_data[, pr] - stanData_classic$pr_mu)/stanData_classic$pr_sd
	stanData_classic$tas_new = (tree_data[, tas] - stanData_classic$tas_mu)/stanData_classic$tas_sd
	stanData_classic$ph_new = (tree_data[, ph] - stanData_classic$ph_mu)/stanData_classic$ph_sd
	stanData_classic$basal_new = rep(0, tree_data[, .N]) # Corresponds to average basal area on the std scale

	# ------ Add indices
	# --------- SSM
	stanData_ssm$start_ind = start_ind
	stanData_ssm$end_ind = end_ind

	# --------- Classic
	stanData_classic$start_ind = start_ind
	stanData_classic$end_ind = end_ind

	# Run predictions
	# --- SSM
	savingGQ_file = paste0(tree_path, "GQ-run=", run, "_main_fr-de-se.rds")
	if (!file.exists(savingGQ_file))
	{
		generate_quantities_ssm = gq_model_ssm$generate_quantities(ssm$draws(), data = stanData_ssm, parallel_chains = n_chains)
	} else {
		print("Quantities already generated, just reading file ssm")
		generate_quantities_ssm = readRDS(savingGQ_file)
	}

	predicted_growth_ssm = stanData_ssm$sd_dbh * generate_quantities_ssm$draws("simulatedGrowth")
	predicted_growth_avg_ssm = stanData_ssm$sd_dbh * generate_quantities_ssm$draws("simulatedGrowth_avg")

	predicted_growth_avg_ssm_avg = apply(X = predicted_growth_avg_ssm, MARGIN = 3, FUN = mean)
	predicted_growth_ssm_avg = apply(X = predicted_growth_ssm, MARGIN = 3, FUN = mean)

	if (!file.exists(savingGQ_file))
	{
		generate_quantities_ssm$save_output_files(dir = tree_path, basename = paste0("GQ-run=", run), timestamp = FALSE, random = TRUE)
		generate_quantities_ssm$save_object(file = paste0(tree_path, "GQ-run=", run, "_main_fr-de-se.rds"))
	}

	# --- Classic
	savingGQ_file = paste0(tree_path, "GQ-run=", run, "_main_classic_fr-de-se.rds")
	if (!file.exists(savingGQ_file))
	{
		generate_quantities_classic = gq_model_classic$generate_quantities(classic$draws(), data = stanData_classic, parallel_chains = n_chains)
	} else {
		print("Quantities already generated, just reading file classic")
		generate_quantities_classic = readRDS(savingGQ_file)
	}

	predicted_growth_classic = stanData_classic$sd_dbh * generate_quantities_classic$draws("simulatedGrowth")
	predicted_growth_avg_classic = stanData_classic$sd_dbh * generate_quantities_classic$draws("simulatedGrowth_avg")

	predicted_growth_avg_classic_avg = apply(X = predicted_growth_avg_classic, MARGIN = 3, FUN = mean)
	predicted_growth_classic_avg = apply(X = predicted_growth_classic, MARGIN = 3, FUN = mean)

	if (!file.exists(savingGQ_file))
	{
		generate_quantities_classic$save_output_files(dir = tree_path, basename = paste0("GQ-run=", run), timestamp = FALSE, random = TRUE)
		generate_quantities_classic$save_object(file = savingGQ_file)
	}

	# Compute correlations
	# --- Pearson
	dt_correl = correl_SSM_classic_data(predicted_growth_ssm_avg, predicted_growth_classic_avg, tree_data)
	dt_correl_avg = correl_SSM_classic_data(predicted_growth_avg_ssm_avg, predicted_growth_avg_classic_avg, tree_data)

	# --- Spearman
	dt_correl_spearman = correl_SSM_classic_data(predicted_growth_ssm_avg, predicted_growth_classic_avg, tree_data, method = "spearman")
	dt_correl_spearman_avg = correl_SSM_classic_data(predicted_growth_avg_ssm_avg, predicted_growth_avg_classic_avg, tree_data, method = "spearman")

	saveRDS(dt_correl, paste0(tree_path, "dt_correl_fr-de-se.rds"))
	saveRDS(dt_correl_avg, paste0(tree_path, "dt_correl_avg_fr-de-se.rds"))
	saveRDS(dt_correl_spearman, paste0(tree_path, "dt_correl_spearman_fr-de-se.rds"))
	saveRDS(dt_correl_spearman_avg, paste0(tree_path, "dt_correl_spearman_avg_fr-de-se.rds"))
}

## Function to give species-specific range and dataset range of predictors and dbh
infoSpecies = function(treeData_folder = "/home/amael/project_ssm/inventories/growth/", clim_folder = treeData_folder,
	soil_folder = treeData_folder, standBasalArea_folder = treeData_folder)
{
	# Load data
	if (!dir.exists(treeData_folder))
		stop(paste0("Folder\n\t", treeData_folder, "\ndoes not exist"))

	if (!dir.exists(clim_folder))
		stop(paste0("Folder\n\t", clim_folder, "\ndoes not exist"))

	if (!dir.exists(soil_folder))
		stop(paste0("Folder\n\t", soil_folder, "\ndoes not exist"))
	
	if (!dir.exists(standBasalArea_folder))
		stop(paste0("Folder\n\t", standBasalArea_folder, "\ndoes not exist"))
	
	treeData = readRDS(paste0(treeData_folder, "standardised_european_growth_data_reshaped.rds"))
	setindex(treeData, speciesName_sci)

	# Create info data table
	# --- Species names and number of individuals
	info = unique(treeData[, .(speciesName_sci, plot_id, tree_id)])[, .(n_indiv = .N), by = speciesName_sci]

	# --- Order and set id which corresponds to the id used in the bash program
	setkey(info, speciesName_sci)
	info[, species_id := seq_len(.N)]

	# --- Number of plots per species
	info[, n_plots := treeData[speciesName_sci, length(unique(plot_id)), on = "speciesName_sci"], by = speciesName_sci]

	# --- Number and list of NFIs per species
	info[, n_nfi := treeData[speciesName_sci, length(unique(nfi_id)), on = "speciesName_sci"], by = speciesName_sci]

	info[, ls_nfi := paste(treeData[speciesName_sci, unique(nfi_id), on = "speciesName_sci"], collapse = ", "), by = speciesName_sci]
	info[, ls_countries := paste(treeData[speciesName_sci, unique(country), on = "speciesName_sci"], collapse = ", "), by = speciesName_sci]

	# --- dbh range per species
	info[, min_dbh := treeData[speciesName_sci, min(dbh), on = "speciesName_sci"], by = speciesName_sci]
	info[, max_dbh := treeData[speciesName_sci, max(dbh), on = "speciesName_sci"], by = speciesName_sci]

	# Run for each species the function indices_subsample with run = "full" (i.e., no subsampling), and extract min-max of explanatory variables
	setkey(treeData, plot_id, tree_id, year)
	source("./indices_subsample.R")

	# --- Load climate	
	climate = readRDS(paste0(clim_folder, "europe_reshaped_climate.rds"))
	setkey(climate, plot_id, year)
	climate[, row_id := seq_len(.N)]

	# --- Read soil data (pH)
	soil = readRDS(paste0(soil_folder, "europe_reshaped_soil.rds"))
	setkey(soil, plot_id)

	# --- Read interpolated basal area data
	standBasalArea = readRDS(paste0(standBasalArea_folder, "europe_reshaped_standBasalArea.rds"))
	setkey(standBasalArea, plot_id)

	# --- Add range columns for environment variables
	info[, c("pr_min", "pr_max", "tas_min", "tas_max", "ph_min", "ph_max", "ba_min", "ba_max") := NaN]
	range_subset = data.table(speciesName_sci = info[, speciesName_sci])
	
	var_runs = paste0(rep(c("pr_", "tas_", "ph_"), each = 2), c("025_", "975_"))
	var_runs = paste0(rep(var_runs, each = 4), 1:4)
	for (currentVar in var_runs)
		set(range_subset, i = NULL, j = currentVar, value = rep(NaN, info[, .N]))

	setkey(range_subset, speciesName_sci)

	# --- Compute indices
	for (species in info[, speciesName_sci])
	{
		species_folder = paste0("./", species, "/")
		if (!file.exists(paste0(species_folder, "full_indices.rds")))
		{
			indices = indices_subsample("full", treeData[speciesName_sci == species], climate, species_folder, treeData_folder, clim_folder)
		} else {
			indices = readRDS(paste0(species_folder, "full_indices.rds"))
		}

		col_start = unique(indices[["indices"]][["index_clim_start"]])
		col_end = unique(indices[["indices"]][["index_clim_end"]])

		if (length(col_start) != length(col_end))
			stop("Starting and ending indices length mismatches")

		rowsToKeep = integer(length = sum(col_end - col_start + 1))
		count = 1
		for (i in seq_along(col_start))
		{
			rowsToKeep[count:(count + col_end[i] - col_start[i])] = col_start[i]:col_end[i]
			count = count + col_end[i] - col_start[i] + 1
		}

		info[species, c("pr_min", "pr_max") := .(unlist(climate[rowsToKeep, lapply(.SD, min, na.rm = TRUE), .SDcols = "pr"]),
			unlist(climate[rowsToKeep, lapply(.SD, max, na.rm = TRUE), .SDcols = "pr"]))]

		info[species, c("tas_min", "tas_max") := .(unlist(climate[rowsToKeep, lapply(.SD, min, na.rm = TRUE), .SDcols = "tas"]),
			unlist(climate[rowsToKeep, lapply(.SD, max, na.rm = TRUE), .SDcols = "tas"]))]

		soil_sp = soil[treeData[, unique(plot_id)], ph]
		info[species, c("ph_min", "ph_max") := .(min(soil_sp), max(soil_sp))]
		
		standBasalArea_sp = standBasalArea[treeData[, unique(plot_id)], standBasalArea_interp]
		info[species, c("ba_min", "ba_max") := .(min(standBasalArea_sp), max(standBasalArea_sp))]

		for (run in 1:4)
		{
			ind_file = paste0(species_folder, run, "_indices.rds")
			if (file.exists(ind_file))
			{
				ind_run = readRDS(ind_file)[["indices"]]
				speciesData = readRDS(paste0(species_folder, run, "_treeData.rds"))
			} else {
				next
			}
			col_start = unique(ind_run[["index_clim_start"]])
			col_end = unique(ind_run[["index_clim_end"]])

			if (length(col_start) != length(col_end))
				stop("Starting and ending indices length mismatches")

			rowsToKeep = integer(length = sum(col_end - col_start + 1))
			count = 1
			for (i in seq_along(col_start))
			{
				rowsToKeep[count:(count + col_end[i] - col_start[i])] = col_start[i]:col_end[i]
				count = count + col_end[i] - col_start[i] + 1
			}

			current_cols = paste0(c("pr_025_", "pr_975_"), run)
			range_subset[species, c(current_cols) :=
				.(unlist(climate[rowsToKeep, lapply(.SD, quantile, na.rm = TRUE, probs = 0.025), .SDcols = "pr"]),
				unlist(climate[rowsToKeep, lapply(.SD, quantile, na.rm = TRUE, probs = 0.975), .SDcols = "pr"]))]

			current_cols = paste0(c("tas_025_", "tas_975_"), run)
			range_subset[species, c(current_cols) :=
				.(unlist(climate[rowsToKeep, lapply(.SD, quantile, na.rm = TRUE, probs = 0.025), .SDcols = "tas"]),
				unlist(climate[rowsToKeep, lapply(.SD, quantile, na.rm = TRUE, probs = 0.975), .SDcols = "tas"]))]

			soil_sp = soil[speciesData[, unique(plot_id)], ph]
			current_cols = paste0(c("ph_025_", "ph_975_"), run)
			range_subset[species, c(current_cols) := .(quantile(soil_sp, probs = 0.025), quantile(soil_sp, probs = 0.975))]
			
			standBasalArea_sp = standBasalArea[speciesData[, unique(plot_id)], standBasalArea_interp]
			current_cols = paste0(c("ba_025_", "ba_975_"), run)
			range_subset[species, c(current_cols) := .(quantile(standBasalArea_sp, probs = 0.025), quantile(standBasalArea_sp, probs = 0.975))]
		}
		print(paste("Species", species, "done"))
	}

	# Save informations
	saveRDS(info, "./speciesInformations.rds")
	saveRDS(range_subset, "./speciesInformations_runs.rds")
	return (list(info = info, range_subset = range_subset))
}
